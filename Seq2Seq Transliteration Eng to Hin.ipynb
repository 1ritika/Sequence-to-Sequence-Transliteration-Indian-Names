{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZ39Vxvm7S0a"
      },
      "source": [
        "#Sequence-to-Sequence Modeling  \n",
        "\n",
        "Perform the task of translating Indian Names to English, a sequence-to-sequence modeling task, using character-level conditional language models.\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JmPFqkT7S0r"
      },
      "source": [
        "**Important Notes**:\n",
        "\n",
        "- Some of the tasks are compute intensive, and are better performed on an accelerator device (GPU, etc.). Unless you have one locally, prefer using a GPU instance on Colab for execution.\n",
        "- Due to resource restrictions on Colab, training some models may not finish in time. In such a case, ensure you store checkpoints to a persistent directory so that you may resume training once your resource limits are restored."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "puFcXNQD2ItL"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TbZjfBWF7S0t"
      },
      "source": [
        "## Outline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQVZHQIJ7S0t"
      },
      "source": [
        "Neural language models are able to successfully capture patterns across Indian names. In this assignment, you will extend upon that idea to learn conditional language models for the task of transliteration: converting Indian names in the English alphabet to Hindi."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ElSrTdBy7S0u"
      },
      "source": [
        "### Tasks\n",
        "\n",
        "- Agnostic Task-Specific Training\n",
        "- Seq-2-Seq via RNN\n",
        "- Seq-2-Seq via RNN with Attention\n",
        "- Evaluation\n",
        "- Decoding Strategy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oeose21P7S0v"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1ApHWVd7S0v"
      },
      "source": [
        "The following cells perform the basic setup such as importing the necessary packages. You will not require any additional libraries, so importing any additional libraries is not allowed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m1rW15no7S0w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc423be5-a4a9-4a0d-d754-3dbd616effcf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "# Installs packages, if using locally. Feel free to add other missing packages as required.\n",
        "\n",
        "%pip install tqdm nltk matplotlib numpy pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NijuBljo7S0w"
      },
      "outputs": [],
      "source": [
        "# Built-in imports, no installations required.\n",
        "\n",
        "import os\n",
        "import gc\n",
        "import json\n",
        "import math\n",
        "import pickle\n",
        "import subprocess\n",
        "import collections\n",
        "import unicodedata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z2liLT4Y7S0x"
      },
      "outputs": [],
      "source": [
        "# 3rd-party package imports, may require installation if not on a platform such as Colab.\n",
        "\n",
        "import numpy\n",
        "import torch\n",
        "import pandas as pd\n",
        "import tqdm.auto as tqdm\n",
        "\n",
        "import matplotlib\n",
        "from matplotlib import pyplot\n",
        "from nltk.translate import bleu_score\n",
        "from torch.utils.data import TensorDataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m3XUKaQ37S0x"
      },
      "outputs": [],
      "source": [
        "# Please do not change anything in the following cell\n",
        "\n",
        "# Find and load fonts that can display Hindi characters, for Matplotlib\n",
        "result = subprocess.run([ 'fc-list', ':lang=hi', 'family' ], capture_output=True)\n",
        "found_hindi_fonts = result.stdout.decode('utf-8').strip().split('\\n')\n",
        "\n",
        "matplotlib.rcParams['font.sans-serif'] = [\n",
        "    'Source Han Sans TW', 'sans-serif', 'Arial Unicode MS',\n",
        "    *found_hindi_fonts\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x2X96lFz7S0y"
      },
      "outputs": [],
      "source": [
        "# Please do not change anything in the following cell\n",
        "\n",
        "DIRECTORY_NAME = f\"{STUDENT_SAP_NAME.replace(' ', '_')}_{STUDENT_SR_NUMBER}\"\n",
        "\n",
        "os.makedirs(DIRECTORY_NAME, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bw94_afp7S0y"
      },
      "outputs": [],
      "source": [
        "def sync_vram():\n",
        "    \"\"\" Synchronizes the VRAM across the GPUs, reclaiming unused memory. \"\"\"\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "    torch.cuda.synchronize()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CEg1ZOP17S0y"
      },
      "source": [
        "## Data Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m_lcFfUf7S0y"
      },
      "source": [
        "We'll load the data for the task, which comprises of a parallel corpus of Indian Names and their Hindi equivalents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gFbB8qWx7S0z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "778eb762-a459-40b3-87b6-f9506f7324f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-03-30 07:55:35--  https://docs.google.com/spreadsheets/d/e/2PACX-1vQOYe_Oy8eMzVFYq6hBSyPLslqA1PeMeK8S5nPs2-viuCNzx0i3Fl_ptFmD0YD3kTA_olYdOIx7iPOh/pub?gid=1482240395&single=true&output=csv\n",
            "Resolving docs.google.com (docs.google.com)... 142.251.175.138, 142.251.175.102, 142.251.175.139, ...\n",
            "Connecting to docs.google.com (docs.google.com)|142.251.175.138|:443... connected.\n",
            "HTTP request sent, awaiting response... 307 Temporary Redirect\n",
            "Location: https://doc-08-6c-sheets.googleusercontent.com/pub/54bogvaave6cua4cdnls17ksc4/0sa1ehic1geq5f1tnhk8int7vg/1743321335000/118252164104506406045/*/e@2PACX-1vQOYe_Oy8eMzVFYq6hBSyPLslqA1PeMeK8S5nPs2-viuCNzx0i3Fl_ptFmD0YD3kTA_olYdOIx7iPOh?gid=1482240395&single=true&output=csv [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2025-03-30 07:55:37--  https://doc-08-6c-sheets.googleusercontent.com/pub/54bogvaave6cua4cdnls17ksc4/0sa1ehic1geq5f1tnhk8int7vg/1743321335000/118252164104506406045/*/e@2PACX-1vQOYe_Oy8eMzVFYq6hBSyPLslqA1PeMeK8S5nPs2-viuCNzx0i3Fl_ptFmD0YD3kTA_olYdOIx7iPOh?gid=1482240395&single=true&output=csv\n",
            "Resolving doc-08-6c-sheets.googleusercontent.com (doc-08-6c-sheets.googleusercontent.com)... 74.125.24.132, 2404:6800:4003:c03::84\n",
            "Connecting to doc-08-6c-sheets.googleusercontent.com (doc-08-6c-sheets.googleusercontent.com)|74.125.24.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/csv]\n",
            "Saving to: ‘data.train.csv’\n",
            "\n",
            "data.train.csv          [  <=>               ] 113.10K   562KB/s    in 0.2s    \n",
            "\n",
            "2025-03-30 07:55:38 (562 KB/s) - ‘data.train.csv’ saved [115815]\n",
            "\n",
            "--2025-03-30 07:55:38--  https://docs.google.com/spreadsheets/d/e/2PACX-1vTKa_jeysYhx869fmTb7VUchlSiChUq0vqotWRGMmnTXWZ8H2PkF8s6hRr2vdo6v54JJx8CEuVo8MZ3/pub?gid=1579594041&single=true&output=csv\n",
            "Resolving docs.google.com (docs.google.com)... 142.251.175.138, 142.251.175.102, 142.251.175.139, ...\n",
            "Connecting to docs.google.com (docs.google.com)|142.251.175.138|:443... connected.\n",
            "HTTP request sent, awaiting response... 307 Temporary Redirect\n",
            "Location: https://doc-08-6c-sheets.googleusercontent.com/pub/54bogvaave6cua4cdnls17ksc4/t50nn666nch5h4me9eli52ic5c/1743321340000/118252164104506406045/*/e@2PACX-1vTKa_jeysYhx869fmTb7VUchlSiChUq0vqotWRGMmnTXWZ8H2PkF8s6hRr2vdo6v54JJx8CEuVo8MZ3?gid=1579594041&single=true&output=csv [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2025-03-30 07:55:40--  https://doc-08-6c-sheets.googleusercontent.com/pub/54bogvaave6cua4cdnls17ksc4/t50nn666nch5h4me9eli52ic5c/1743321340000/118252164104506406045/*/e@2PACX-1vTKa_jeysYhx869fmTb7VUchlSiChUq0vqotWRGMmnTXWZ8H2PkF8s6hRr2vdo6v54JJx8CEuVo8MZ3?gid=1579594041&single=true&output=csv\n",
            "Resolving doc-08-6c-sheets.googleusercontent.com (doc-08-6c-sheets.googleusercontent.com)... 74.125.24.132, 2404:6800:4003:c03::84\n",
            "Connecting to doc-08-6c-sheets.googleusercontent.com (doc-08-6c-sheets.googleusercontent.com)|74.125.24.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/csv]\n",
            "Saving to: ‘data.valid.csv’\n",
            "\n",
            "data.valid.csv          [ <=>                ]  10.10K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-03-30 07:55:40 (68.7 MB/s) - ‘data.valid.csv’ saved [10342]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Make sure your code is not dependent on any of the file names as below.\n",
        "\n",
        "# Download the training and validation datasets\n",
        "!wget -O data.train.csv \"https://docs.google.com/spreadsheets/d/e/2PACX-1vQOYe_Oy8eMzVFYq6hBSyPLslqA1PeMeK8S5nPs2-viuCNzx0i3Fl_ptFmD0YD3kTA_olYdOIx7iPOh/pub?gid=1482240395&single=true&output=csv\"\n",
        "!wget -O data.valid.csv \"https://docs.google.com/spreadsheets/d/e/2PACX-1vTKa_jeysYhx869fmTb7VUchlSiChUq0vqotWRGMmnTXWZ8H2PkF8s6hRr2vdo6v54JJx8CEuVo8MZ3/pub?gid=1579594041&single=true&output=csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1L8ZDlFm7S0z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a683f9a2-d494-4564-e619-d8b3e2371a67"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of training data: 4484\n",
            "Length of validation data: 400\n"
          ]
        }
      ],
      "source": [
        "# Please do not change anything in the following cell\n",
        "\n",
        "def read_dataframe(ds_type):\n",
        "    \"\"\" Loads a dataframe based on the given partition type.\n",
        "\n",
        "    Args:\n",
        "        ds_type (str): Dataset type: train (train) or validation (valid)\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: Pandas Dataframe for the specified partition.\n",
        "    \"\"\"\n",
        "\n",
        "    df = pd.read_csv(f\"data.{ds_type}.csv\", header=0)\n",
        "    df = df[~df.isna()]\n",
        "    df['Name'] = df['Name'].astype(str)\n",
        "    df['Translation'] = df['Translation'].astype(str)\n",
        "    return df\n",
        "\n",
        "# Load the training and validation datasets\n",
        "train_data      = read_dataframe(\"train\")\n",
        "validation_data = read_dataframe(\"valid\")\n",
        "\n",
        "print(f\"Length of training data: {len(train_data)}\\nLength of validation data: {len(validation_data)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LE8sRvHo7S00"
      },
      "source": [
        "Here are some examples from the training dataset. Note that the dataset may be noisy so some examples may not be perfect:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kZH2EVyE7S00",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82b30125-9a76-4900-ec5b-51045cc154bb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            Name  Translation\n",
              "330         हरिब        harib\n",
              "2790       पाटिक        patik\n",
              "59          संतु        santu\n",
              "4441  राधेयश्याम  radheyshyam\n",
              "2689        सोने         sone"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4a1e6aac-cb70-4116-963a-244430dffafc\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Name</th>\n",
              "      <th>Translation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>330</th>\n",
              "      <td>हरिब</td>\n",
              "      <td>harib</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2790</th>\n",
              "      <td>पाटिक</td>\n",
              "      <td>patik</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>संतु</td>\n",
              "      <td>santu</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4441</th>\n",
              "      <td>राधेयश्याम</td>\n",
              "      <td>radheyshyam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2689</th>\n",
              "      <td>सोने</td>\n",
              "      <td>sone</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4a1e6aac-cb70-4116-963a-244430dffafc')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4a1e6aac-cb70-4116-963a-244430dffafc button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4a1e6aac-cb70-4116-963a-244430dffafc');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9f22ae65-6e3d-43e5-9034-ffb023d08f44\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9f22ae65-6e3d-43e5-9034-ffb023d08f44')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9f22ae65-6e3d-43e5-9034-ffb023d08f44 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"train_data\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"\\u092a\\u093e\\u091f\\u093f\\u0915\",\n          \"\\u0938\\u094b\\u0928\\u0947\",\n          \"\\u0938\\u0902\\u0924\\u0941\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Translation\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"patik\",\n          \"sone\",\n          \"santu\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "train_data.sample(n=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0B5XhUx7S01"
      },
      "source": [
        "## Tokenization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wizKxo-j7S01"
      },
      "source": [
        "An implementation of tokenization is already in place. Do not modify it, as it can affect your evaluation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Y3ri4PD7S02"
      },
      "outputs": [],
      "source": [
        "# Please do not change anything in the following cell\n",
        "\n",
        "class Tokenizer:\n",
        "    \"\"\" Represents the tokenizer for text data.\n",
        "        Provides methods to encode and decode strings (as instance or as a batch). \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\" Initializes a new tokenizer.\n",
        "\n",
        "            Any variables required in intermediate operations are declared here.\n",
        "            You will also need to define things like special tokens and other things here.\n",
        "\n",
        "            All variables declared in this function will be serialized\n",
        "                and deserialized when loading and saving the Tokenizer.\n",
        "            \"\"\"\n",
        "\n",
        "        self.special_tokens = { '[BOS]': 1, '[EOS]': 2, '[PAD]': 0 }\n",
        "        self.vocab = { bytes([ i ]): i+len(self.special_tokens) for i in range(256)  }\n",
        "        self.merge_rules = {  }\n",
        "        self.inv_vocab = { _id: token for token, _id in self.vocab.items() }\n",
        "        self.inv_vocab.update({ _id: token.encode() for token, _id in self.special_tokens.items() })\n",
        "\n",
        "    @classmethod\n",
        "    def load(cls, path):\n",
        "        \"\"\" Loads a pre-trained tokenizer from the given directory.\n",
        "           This directory will have a tokenizer.pkl file that contains all the tokenizer variables.\n",
        "\n",
        "        Args:\n",
        "            path (str): Path to load the tokenizer from.\n",
        "        \"\"\"\n",
        "        tokenizer_file = os.path.join(path, \"tokenizer.pkl\")\n",
        "\n",
        "        if not os.path.exists(path) or not os.path.exists(os.path.join(path, \"tokenizer.pkl\")):\n",
        "            raise ValueError(cls.load.__name__ + \": No tokenizer found at the specified directory\")\n",
        "\n",
        "        with open(tokenizer_file, \"rb\") as ifile:\n",
        "            return pickle.load(ifile)\n",
        "\n",
        "    def save(self, path):\n",
        "        \"\"\" Saves a trained tokenizer to a given directory, inside a tokenizer.pkl file.\n",
        "\n",
        "        Args:\n",
        "            path (str): Directory to save the tokenizer in.\n",
        "        \"\"\"\n",
        "\n",
        "        os.makedirs(path, exist_ok=True)\n",
        "        with open(os.path.join(path, \"tokenizer.pkl\"), 'wb') as ofile:\n",
        "            pickle.dump(self, ofile)\n",
        "\n",
        "    def train(self, data, vocab_size):\n",
        "        \"\"\" Trains a tokenizer to learn meaningful representations from input data.\n",
        "            In the end, learns a vocabulary of a fixed size over the given data.\n",
        "            Special tokens, if any, must not be counted towards this vocabulary.\n",
        "\n",
        "        Args:\n",
        "            data (list[str]): List of input strings from a text corpus.\n",
        "            vocab_size (int): Final desired size of the vocab to be learnt.\n",
        "        \"\"\"\n",
        "\n",
        "        self.vocab = { bytes([ i ]): i+len(self.special_tokens) for i in range(256)  }\n",
        "        self.vocab.update({ token.encode('utf-8'): _id for token, _id in self.special_tokens.items() })\n",
        "\n",
        "        self.merge_rules = {  }\n",
        "        self.inv_vocab   = { _id: token for token, _id in self.vocab.items() }\n",
        "\n",
        "        data = [ [ i+len(self.special_tokens) for i in instance.encode('utf-8') ] for instance in data ]\n",
        "\n",
        "        while len(self.vocab) < len(self.special_tokens) + vocab_size:\n",
        "            # Compute stats\n",
        "            counts = collections.defaultdict(int)\n",
        "            for tok_str in data:\n",
        "                for tok, next_tok in zip(tok_str, tok_str[1:]):\n",
        "                    counts[(tok, next_tok)] += 1\n",
        "\n",
        "            # Learn a new merge rule\n",
        "            best_pair = max(counts, key=counts.get)\n",
        "            new_token, new_id = self.inv_vocab[best_pair[0]] + self.inv_vocab[best_pair[1]], len(self.vocab)\n",
        "            self.merge_rules[best_pair] = new_id\n",
        "            self.inv_vocab[new_id] = new_token\n",
        "            self.vocab[new_token]  = new_id\n",
        "\n",
        "            # Update tokens\n",
        "            new_data = []\n",
        "            for tok_str in data:\n",
        "                i, new_tok_str = 0, []\n",
        "                while i < len(tok_str):\n",
        "                    if i < len(tok_str) - 1 and (tok_str[i], tok_str[i+1]) == best_pair:\n",
        "                        new_tok_str.append(new_id)\n",
        "                        i += 2\n",
        "                    else:\n",
        "                        new_tok_str.append(tok_str[i])\n",
        "                        i += 1\n",
        "                new_data.append(new_tok_str)\n",
        "            data = new_data\n",
        "\n",
        "    def pad(self, tokens, length):\n",
        "        \"\"\" Pads a tokenized string to a specified length, for batch processing.\n",
        "\n",
        "        Args:\n",
        "            tokens (list[int]): Encoded token string to be padded.\n",
        "            length (int): Length of tokens to pad to.\n",
        "\n",
        "        Returns:\n",
        "            list[int]: Token string padded to desired length.\n",
        "        \"\"\"\n",
        "\n",
        "\n",
        "        if len(tokens) < length:\n",
        "            tokens = [ *tokens ]\n",
        "            tokens += ([ self.special_tokens['[PAD]'] ] * (length - len(tokens)))\n",
        "\n",
        "        return tokens\n",
        "\n",
        "\n",
        "    def unpad(self, tokens):\n",
        "        \"\"\" Removes padding from a token string.\n",
        "\n",
        "        Args:\n",
        "            tokens (list[int]): Encoded token string with padding.\n",
        "\n",
        "        Returns:\n",
        "            list[int]: Token string with padding removed.\n",
        "        \"\"\"\n",
        "\n",
        "        no_pad_len = len(tokens)\n",
        "        while tokens[no_pad_len-1] == self.special_tokens['[PAD]']: no_pad_len -= 1\n",
        "\n",
        "        return tokens[:no_pad_len]\n",
        "\n",
        "    def get_special_tokens(self):\n",
        "        \"\"\" Returns the associated special tokens.\n",
        "\n",
        "            Returns:\n",
        "                dict[str, int]: Mapping describing the special tokens, if any.\n",
        "                    This is a mapping between a string segment (token) and its associated id (token_id).\n",
        "        \"\"\"\n",
        "\n",
        "        return self.special_tokens\n",
        "\n",
        "    def get_vocabulary(self):\n",
        "        \"\"\" Returns the learnt vocabulary post the training process.\n",
        "\n",
        "            Returns:\n",
        "                dict[str, int]: Mapping describing the vocabulary and special tokens, if any.\n",
        "                    This is a mapping between a string segment (token) and its associated id (token_id).\n",
        "        \"\"\"\n",
        "\n",
        "        return self.vocab\n",
        "\n",
        "    def encode(self, string, add_start=True, add_end=True):\n",
        "        \"\"\" Encodes a string into a list of tokens.\n",
        "\n",
        "        Args:\n",
        "            string (str): Input string to be tokenized.\n",
        "            add_start (bool): If true, adds the start of sequence token.\n",
        "            add_end (bool): If true, adds the end of sequence token.\n",
        "        Returns:\n",
        "            list[int]: List of tokens (unpadded).\n",
        "        \"\"\"\n",
        "\n",
        "        string = unicodedata.normalize('NFKC', string)\n",
        "\n",
        "        tokens = [ i+len(self.special_tokens) for i in string.encode('utf-8') ]\n",
        "\n",
        "        while len(tokens) > 1:\n",
        "            pairs = set()\n",
        "            for tok, next_tok in zip(tokens, tokens[1:]):\n",
        "                pairs.add((tok, next_tok))\n",
        "\n",
        "            merge_pair = min(pairs, key=lambda x: self.merge_rules.get(x, float(\"inf\")))\n",
        "            if merge_pair not in self.merge_rules: break\n",
        "\n",
        "            i, new_tokens = 0, []\n",
        "            while i < len(tokens):\n",
        "                if i < len(tokens) - 1 and (tokens[i], tokens[i+1]) == merge_pair:\n",
        "                    new_tokens.append(self.merge_rules[merge_pair])\n",
        "                    i += 2\n",
        "                else:\n",
        "                    new_tokens.append(tokens[i])\n",
        "                    i += 1\n",
        "            tokens = new_tokens\n",
        "\n",
        "        if add_start: tokens = [ self.special_tokens['[BOS]'] ] + tokens\n",
        "        if add_end  : tokens = tokens + [ self.special_tokens['[EOS]'] ]\n",
        "\n",
        "        return tokens\n",
        "\n",
        "\n",
        "    def decode(self, tokens, strip_special=True):\n",
        "        \"\"\" Decodes a string from a list of tokens.\n",
        "            Undoes the tokenization, returning back the input string.\n",
        "\n",
        "        Args:\n",
        "            tokens (list[int]): List of encoded tokens to be decoded. No padding is assumed.\n",
        "            strip_special (bool): Whether to remove special tokens or not.\n",
        "\n",
        "        Returns:\n",
        "            str: Decoded string.\n",
        "        \"\"\"\n",
        "\n",
        "        if strip_special:\n",
        "            special_tokens = set(self.special_tokens.values())\n",
        "            tokens = [ token for token in tokens if token not in special_tokens ]\n",
        "\n",
        "        return (b''.join(self.inv_vocab[tok_id] for tok_id in tokens)).decode('utf-8', errors='replace')\n",
        "\n",
        "    def batch_encode(self, batch, padding=None, add_start=True, add_end=True):\n",
        "        \"\"\"Encodes multiple strings in a batch to list of tokens padded to a given size.\n",
        "\n",
        "        Args:\n",
        "            batch (list[str]): List of strings to be tokenized.\n",
        "            padding (int, optional): Optional, desired tokenized length. Outputs will be padded to fit this length.\n",
        "            add_start (bool): If true, adds the start of sequence token.\n",
        "            add_end (bool): If true, adds the end of sequence token.\n",
        "\n",
        "        Returns:\n",
        "            list[list[int]]: List of tokenized outputs, padded to the same length.\n",
        "        \"\"\"\n",
        "\n",
        "        batch_output = [ self.encode(string, add_start, add_end) for string in batch ]\n",
        "        if padding:\n",
        "            for i, tokens in enumerate(batch_output):\n",
        "                if len(tokens) < padding:\n",
        "                    batch_output[i] = self.pad(tokens, padding)\n",
        "        return batch_output\n",
        "\n",
        "    def batch_decode(self, batch, strip_special=True):\n",
        "        \"\"\" Decodes a batch of encoded tokens to normal strings.\n",
        "\n",
        "        Args:\n",
        "            batch (list[list[int]]): List of encoded token strings, optionally padded.\n",
        "            strip_special (bool): Whether to remove special tokens or not.\n",
        "\n",
        "        Returns:\n",
        "            list[str]: Decoded strings after padding is removed.\n",
        "        \"\"\"\n",
        "        return [ self.decode(self.unpad(tokens), strip_special=strip_special) for tokens in batch ]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2__Tts8p7S04"
      },
      "source": [
        "Now with the tokenizer class, initialize and train the tokenizers for processing the parallel corpus:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4A_U8cl_7S04"
      },
      "outputs": [],
      "source": [
        "# Please do not change anything in the following cell\n",
        "\n",
        "# Initialize the tokenizers as per the desired strategy.\n",
        "src_tokenizer = Tokenizer()\n",
        "tgt_tokenizer = Tokenizer()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OBYyr0Es7S04"
      },
      "outputs": [],
      "source": [
        "# Please do not change anything in the following cell\n",
        "\n",
        "# Edit the hyperparameters below as desired.\n",
        "SRC_VOCAB_SIZE = 300\n",
        "TGT_VOCAB_SIZE = 400\n",
        "\n",
        "\n",
        "# Train your tokenizer(s)\n",
        "src_tokenizer.train(train_data['Name']       , vocab_size=SRC_VOCAB_SIZE)\n",
        "tgt_tokenizer.train(train_data['Translation'], vocab_size=TGT_VOCAB_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a2vmqRKH7S05"
      },
      "outputs": [],
      "source": [
        "# Please do not change anything in the following cell\n",
        "\n",
        "# Save the trained tokenizers\n",
        "src_tokenizer.save(os.path.join(DIRECTORY_NAME, \"src-tokenizer\"))\n",
        "tgt_tokenizer.save(os.path.join(DIRECTORY_NAME, \"tgt-tokenizer\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s1O2qJYg7S06"
      },
      "outputs": [],
      "source": [
        "# Please do not change anything in the following cell\n",
        "\n",
        "def render_glyph(token):\n",
        "    \"\"\" Renders a token, handling invalid bytes in a safe, error-proof manner. \"\"\"\n",
        "\n",
        "    token = token.decode('utf-8', errors='replace') if isinstance(token, bytes) else token\n",
        "    return \"\".join([ c if unicodedata.category(c)[0] != \"C\" else f\"\\\\u{ord(c):04x}\" for c in token ])\n",
        "\n",
        "def inverse_vocabulary(tokenizer):\n",
        "    \"\"\" Generates an inverse vocabulary with rendered tokens.\n",
        "\n",
        "    Args:\n",
        "        tokenizer (Tokenizer): Tokenizer whose vocabulary must be used.\n",
        "    \"\"\"\n",
        "\n",
        "    return { id: render_glyph(token) for token, id in tokenizer.get_vocabulary().items() }\n",
        "\n",
        "def apply_inverse_vocab(tokens, inv_vocab):\n",
        "    \"\"\" Decodes using the given inverse vocabulary.\n",
        "\n",
        "    Args:\n",
        "        tokens (list[int]): Tokens to process.\n",
        "        inv_vocab (dict[int, str]): Inverse vocabulary for mapping ids to tokens.\n",
        "\n",
        "    Returns:\n",
        "        list[str]: Mapped token glyphs.\n",
        "    \"\"\"\n",
        "\n",
        "    return [ inv_vocab[id] for id in tokens ]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q3VKC9YY7S06"
      },
      "source": [
        "We visualize a few outputs of the learnt tokenizers to assess their working:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "75gjtCVW7S07",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51556df9-6085-4dc1-f91d-b5e933892281"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name           : दीपक\n",
            "Tokens         : [1, 272, 287, 265, 273, 261, 277, 271, 2]\n",
            "Tokens (glyphs): ['[BOS]', 'श', '्र', 'ी', 'क', 'ा', 'ं', 'त', '[EOS]']\n",
            "Decoded        : श्रीकांत\n",
            "\n",
            "Name           : दामोदर\n",
            "Tokens         : [1, 272, 287, 265, 273, 261, 277, 271, 2]\n",
            "Tokens (glyphs): ['[BOS]', 'श', '्र', 'ी', 'क', 'ा', 'ं', 'त', '[EOS]']\n",
            "Decoded        : श्रीकांत\n",
            "\n",
            "Name           : आमरिन\n",
            "Tokens         : [1, 272, 287, 265, 273, 261, 277, 271, 2]\n",
            "Tokens (glyphs): ['[BOS]', 'श', '्र', 'ी', 'क', 'ा', 'ं', 'त', '[EOS]']\n",
            "Decoded        : श्रीकांत\n",
            "\n",
            "Name           : बनिता\n",
            "Tokens         : [1, 272, 287, 265, 273, 261, 277, 271, 2]\n",
            "Tokens (glyphs): ['[BOS]', 'श', '्र', 'ी', 'क', 'ा', 'ं', 'त', '[EOS]']\n",
            "Decoded        : श्रीकांत\n",
            "\n",
            "Name           : घन्स्याम\n",
            "Tokens         : [1, 272, 287, 265, 273, 261, 277, 271, 2]\n",
            "Tokens (glyphs): ['[BOS]', 'श', '्र', 'ी', 'क', 'ा', 'ं', 'त', '[EOS]']\n",
            "Decoded        : श्रीकांत\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Please do not change anything in the following cell\n",
        "\n",
        "src_id_to_token = inverse_vocabulary(src_tokenizer)\n",
        "\n",
        "for example in train_data['Name'].sample(n=5, random_state=20240227):\n",
        "    print(\"Name           :\", example)\n",
        "    tokens = src_tokenizer.encode(\"श्रीकांत\")\n",
        "    print(\"Tokens         :\", tokens)\n",
        "    print(\"Tokens (glyphs):\", apply_inverse_vocab(tokens, src_id_to_token))\n",
        "    print(\"Decoded        :\", src_tokenizer.decode(tokens), end='\\n\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MJT2frJu7S08",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7495898f-a4eb-4a0c-f464-d2c11ab70ae5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name           : deepak\n",
            "Tokens         : [1, 332, 318, 110, 2]\n",
            "Tokens (glyphs): ['[BOS]', 'dee', 'pa', 'k', '[EOS]']\n",
            "Decoded        : deepak\n",
            "\n",
            "Name           : damodar\n",
            "Tokens         : [1, 103, 264, 114, 103, 261, 2]\n",
            "Tokens (glyphs): ['[BOS]', 'd', 'am', 'o', 'd', 'ar', '[EOS]']\n",
            "Decoded        : damodar\n",
            "\n",
            "Name           : aamrin\n",
            "Tokens         : [1, 100, 264, 117, 265, 2]\n",
            "Tokens (glyphs): ['[BOS]', 'a', 'am', 'r', 'in', '[EOS]']\n",
            "Decoded        : aamrin\n",
            "\n",
            "Name           : banita\n",
            "Tokens         : [1, 101, 259, 327, 2]\n",
            "Tokens (glyphs): ['[BOS]', 'b', 'an', 'ita', '[EOS]']\n",
            "Decoded        : banita\n",
            "\n",
            "Name           : ghansyam\n",
            "Tokens         : [1, 106, 345, 118, 375, 2]\n",
            "Tokens (glyphs): ['[BOS]', 'g', 'han', 's', 'yam', '[EOS]']\n",
            "Decoded        : ghansyam\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Please do not change anything in the following cell\n",
        "\n",
        "tgt_id_to_token = inverse_vocabulary(tgt_tokenizer)\n",
        "\n",
        "for example in train_data['Translation'].sample(n=5, random_state=20240227):\n",
        "    print(\"Name           :\", example)\n",
        "    tokens = tgt_tokenizer.encode(example)\n",
        "    print(\"Tokens         :\", tokens)\n",
        "    print(\"Tokens (glyphs):\", apply_inverse_vocab(tokens, tgt_id_to_token))\n",
        "    print(\"Decoded        :\", tgt_tokenizer.decode(tokens), end='\\n\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dUOLUDqy7S09"
      },
      "source": [
        "We now abstract away the tokenizer into a pytorch compatible TokenizedDataset that will handle the tokenization internally:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0BFaB2Nr7S09"
      },
      "outputs": [],
      "source": [
        "# Please do not change anything in the following cell\n",
        "\n",
        "class TokenizerDataset(TensorDataset):\n",
        "    \"\"\" Abstraction of the tokenizer functions as a pytorch dataset. \"\"\"\n",
        "\n",
        "    def __init__(self, data, src_tokenizer, tgt_tokenizer, src_padding=None, tgt_padding=None):\n",
        "        \"\"\" Initializes the dataset.\n",
        "\n",
        "        Args:\n",
        "            data: DataFrame of input and output strings.\n",
        "            src_tokenizer (Tokenizer): Tokenizer for the source language.\n",
        "            tgt_tokenizer (Tokenizer): Tokenizer for the target language.\n",
        "            src_padding (int, optional): Padding length for the source text. Defaults to None.\n",
        "            tgt_padding (int, optional): Padding length for the target text. Defaults to None.\n",
        "        \"\"\"\n",
        "\n",
        "        self.data = data\n",
        "        self.src_tokenizer = src_tokenizer\n",
        "        self.tgt_tokenizer = tgt_tokenizer\n",
        "        self.src_padding = src_padding\n",
        "        self.tgt_padding = tgt_padding\n",
        "\n",
        "    def collate(self, batch):\n",
        "        \"\"\" Collates data instances into a batch of tokenized tensors.\n",
        "\n",
        "        Args:\n",
        "            batch (list[tuple]): List of x, y pairs.\n",
        "\n",
        "        Returns:\n",
        "            tuple[torch.Tensor|PackedSequence, torch.Tensor|PackedSequence]: pair of tokenized tensors.\n",
        "        \"\"\"\n",
        "\n",
        "        x_batch = [ data[0] for data in batch ]\n",
        "        y_batch = [ data[1] for data in batch ]\n",
        "\n",
        "        x_batch = self.src_tokenizer.batch_encode(x_batch, self.src_padding)\n",
        "        y_batch = self.tgt_tokenizer.batch_encode(y_batch, self.tgt_padding)\n",
        "\n",
        "        if self.src_padding is None:\n",
        "            x_batch = torch.nn.utils.rnn.pack_sequence([ torch.tensor(tokens) for tokens in x_batch ], False)\n",
        "        else:\n",
        "            x_batch = torch.tensor(x_batch)\n",
        "\n",
        "        if self.tgt_padding is None:\n",
        "            y_batch = torch.nn.utils.rnn.pack_sequence([ torch.tensor(tokens) for tokens in y_batch ], False)\n",
        "        else:\n",
        "            y_batch = torch.tensor(y_batch)\n",
        "\n",
        "        return x_batch, y_batch\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\" Returns the nth instance from the dataset.\n",
        "\n",
        "        Args:\n",
        "            index (int): Index of the instance to retrieve.\n",
        "\n",
        "        Returns:\n",
        "            tuple[str, str]: Untokenized instance pair.\n",
        "        \"\"\"\n",
        "\n",
        "        return (\n",
        "            self.data['Name'][index],\n",
        "            self.data['Translation'][index]\n",
        "        )\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\" Returns the length of the dataset.\n",
        "\n",
        "        Returns:\n",
        "            int: Length of the dataset.\n",
        "        \"\"\"\n",
        "        return len(self.data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rBnISg0K7S1G"
      },
      "source": [
        "## Model-Agnostic Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JUF3_vkA7S1G"
      },
      "source": [
        "Next, you'll implement a Trainer to train different models, since the data and tokenizer remains the same for all models.\n",
        "\n",
        "This trainer will receive the model, a loss function, an optimizer, a training and (optionally) a validation dataset and use these to train (and validate) the model.\n",
        "\n",
        "The trainer will also take care of handling checkpoints for training, which can be used to resume training across sessions.\n",
        "\n",
        "Derived classes can also be defined to handle different architectures, as to be done in the model-specific classes below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kcq8zymS7S1H"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "class Trainer:\n",
        "    \"\"\" Performs model training in a model-agnostic manner.\n",
        "        Requires specifying the model instance, the loss criterion to optimize,\n",
        "          the optimizer to use and the directory to save data to.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, directory, model, criterion, optimizer):\n",
        "        \"\"\" Initializes the trainer.\n",
        "\n",
        "        Args:\n",
        "            directory (str): Directory to save checkpoints and the model data in.\n",
        "            model (torch.nn.Module): Torch model (must inherit `torch.nn.Module`) to train.\n",
        "            criterion (torch.nn.Function): Loss criterion, i.e., the loss function to optimize for training.\n",
        "            optimizer (torch.optim.Optimizer): Optimizer to use for training.\n",
        "        \"\"\"\n",
        "\n",
        "        self.model            = model\n",
        "        self.optimizer        = optimizer\n",
        "        self.criterion        = criterion\n",
        "        self.directory        = directory\n",
        "        self.last_checkpoint  = 0\n",
        "        self.loss_history     = { 'train': [], 'valid': [] }\n",
        "\n",
        "        os.makedirs(self.directory, exist_ok=True)\n",
        "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "    @staticmethod\n",
        "    def make_dataloader(dataset, shuffle_data=True, batch_size=8, collate_fn=None):\n",
        "        \"\"\" Create a dataloader for a torch Dataset.\n",
        "\n",
        "        Args:\n",
        "            dataset (torch.utils.data.Dataset): Dataset to process.\n",
        "            shuffle_data (bool, optional): If true, shuffles the data. Defaults to True.\n",
        "            batch_size (int, optional): Number of items per batch. Defaults to 8.\n",
        "            collate_fn (function, optional): Function to use for collating instances to a batch.\n",
        "\n",
        "        Returns:\n",
        "            torch.utils.data.DataLoader: Dataloader over the given data, post processing.\n",
        "        \"\"\"\n",
        "\n",
        "\n",
        "        return torch.utils.data.DataLoader(\n",
        "            dataset,\n",
        "            shuffle=shuffle_data,\n",
        "            batch_size=batch_size,\n",
        "            collate_fn=collate_fn\n",
        "        )\n",
        "    def train_step(self, x_batch, y_batch):\n",
        "        \"\"\" Performs a step of training, on the training batch.\n",
        "\n",
        "        Args:\n",
        "            x_batch (torch.Tensor): Input batch.\n",
        "            y_batch (torch.Tensor): Output batch.\n",
        "\n",
        "        Returns:\n",
        "            float: Training loss with the current model, on this batch.\n",
        "        \"\"\"\n",
        "\n",
        "\n",
        "\n",
        "        x_batch = x_batch.to(self.device)\n",
        "        y_batch = y_batch.to(self.device)\n",
        "        self.optimizer.zero_grad()\n",
        "\n",
        "        out = self.model(x_batch)\n",
        "        out = out.squeeze(-1)             # make shape [B]\n",
        "\n",
        "        tgt = y_batch.reshape(-1)         # flatten target to [B]\n",
        "        l = self.criterion(out, tgt)\n",
        "        l.backward()\n",
        "        self.optimizer.step()\n",
        "        return l.item()\n",
        "\n",
        "\n",
        "\n",
        "    def eval_step(self, validation_dataloader):\n",
        "        \"\"\" Perfoms an evaluation step, on the validation dataloader.\n",
        "\n",
        "        Args:\n",
        "            validation_dataloader (torch.utils.data.DataLoader): Dataloader for the validation dataset.\n",
        "\n",
        "        Returns:\n",
        "            float: Validation loss with the current model checkpoint.\n",
        "        \"\"\"\n",
        "\n",
        "\n",
        "\n",
        "        self.model.eval()\n",
        "        ttl_l = 0\n",
        "        cnt = 0\n",
        "        with torch.no_grad():\n",
        "            for xb, yb in validation_dataloader:\n",
        "                xb = xb.to(self.device)\n",
        "                yb = yb.to(self.device)\n",
        "\n",
        "                out = self.model(xb)\n",
        "                out = out.squeeze(-1)\n",
        "\n",
        "                tgt = yb.reshape(-1)\n",
        "                l = self.criterion(out, tgt)\n",
        "                ttl_l += l.item()\n",
        "                cnt += 1\n",
        "        self.model.train()\n",
        "        return ttl_l / cnt if cnt > 0 else 0.0\n",
        "\n",
        "\n",
        "    def train(self, train_dataset, validation_dataset=None,\n",
        "              num_epochs=10, batch_size=8, shuffle=True,\n",
        "              save_steps=100, eval_steps=100, collate_fn=None):\n",
        "        \"\"\" Handles the training loop for the model.\n",
        "\n",
        "        Args:\n",
        "            train_dataset (torch.utils.data.Dataset): Dataset to train on.\n",
        "            validation_dataset (torch.utils.data.Dataset, optional): Data to validate on. Defaults to None.\n",
        "            num_epochs (int, optional): Number of epochs to train for. Defaults to 10.\n",
        "            batch_size (int, optional): Number of items to process per batch. Defaults to 8.\n",
        "            shuffle (bool, optional): Whether to shuffle the data or not. Defaults to True.\n",
        "            save_steps (int, optional): Number of steps post which a checkpoint should be saved. Defaults to 100.\n",
        "            eval_steps (int, optional): Number of steps post which the model should be evaluated. Defaults to 100.\n",
        "            collate_fn (function, optional): Function to use for collating instances to a batch.\n",
        "        \"\"\"\n",
        "\n",
        "        current_checkpoint = 0\n",
        "        self.model.to(self.device)\n",
        "        self.model.train()\n",
        "\n",
        "        with tqdm.tqdm(total = math.ceil(len(train_dataset) / batch_size) * num_epochs) as pbar:\n",
        "            for epoch in range(num_epochs):\n",
        "                train_dataloader      = self.make_dataloader(train_dataset, shuffle, batch_size, collate_fn)\n",
        "                if validation_dataset is not None:\n",
        "                    validation_dataloader = self.make_dataloader(validation_dataset, shuffle, batch_size, collate_fn)\n",
        "\n",
        "                for batch, (x_batch, y_batch) in enumerate(train_dataloader):\n",
        "                    pbar.set_description(f\"Epoch {epoch+1} / {num_epochs}\")\n",
        "\n",
        "                    # If we are resuming training, skip this iteration\n",
        "                    if current_checkpoint < self.last_checkpoint:\n",
        "                        current_checkpoint += 1\n",
        "                        pbar.update()\n",
        "                        continue\n",
        "\n",
        "                    # Do a step of training\n",
        "                    loss = self.train_step(x_batch, y_batch)\n",
        "                    self.loss_history['train'].append(loss)\n",
        "                    pbar.set_postfix({ 'batch': batch+1, 'loss': loss })\n",
        "\n",
        "                    current_checkpoint += 1\n",
        "                    pbar.update()\n",
        "\n",
        "                    # Evaluate after every eval_steps\n",
        "                    if (current_checkpoint) % eval_steps == 0:\n",
        "                        if validation_dataset is not None:\n",
        "                            val_loss = self.eval_step(validation_dataloader)\n",
        "                            self.loss_history['valid'].append(val_loss)\n",
        "                        else:\n",
        "                            val_loss = None\n",
        "\n",
        "                        print('[>]', f\"epoch #{epoch+1:{len(str(num_epochs))}},\",\n",
        "                              f\"batch #{batch+1:{len(str(len(train_dataloader)))}}:\",\n",
        "                              \"loss:\", f\"{loss:.8f}\", '|', \"val_loss:\", f\"{val_loss:.8f}\")\n",
        "\n",
        "                    # Save after every save_steps\n",
        "                    if (current_checkpoint) % save_steps == 0:\n",
        "                        self.save(current_checkpoint, { 'loss': loss, 'checkpoint': current_checkpoint })\n",
        "\n",
        "                    # free unused resources\n",
        "                    sync_vram()\n",
        "\n",
        "            self.save(current_checkpoint)\n",
        "\n",
        "    def resume(self):\n",
        "        \"\"\" Resumes training session from the most recent checkpoint. \"\"\"\n",
        "\n",
        "        if checkpoints := os.listdir(self.directory):\n",
        "            self.last_checkpoint = max(map(lambda x: int(x[11:]), filter(lambda x: 'checkpoint-' in x, checkpoints)))\n",
        "            checkpoint_dir = os.path.join(self.directory, f\"checkpoint-{self.last_checkpoint}\")\n",
        "            self.model.load_state_dict(torch.load(\n",
        "                os.path.join(checkpoint_dir, \"model.pt\"),\n",
        "                map_location=self.device\n",
        "            ))\n",
        "            self.model.to(self.device)\n",
        "            self.optimizer.load_state_dict(torch.load(\n",
        "                os.path.join(checkpoint_dir, \"optimizer.pt\"),\n",
        "                map_location=self.device\n",
        "            ))\n",
        "            with open(os.path.join(checkpoint_dir, \"loss.json\"), 'r', encoding='utf-8') as ifile:\n",
        "                self.loss_history = json.load(ifile)\n",
        "\n",
        "    def save(self, checkpoint=None, metadata=None):\n",
        "        \"\"\" Saves an associated model or a training checkpoint.\n",
        "\n",
        "            If a checkpoint is specified, saves a checkpoint specific directory with optimizer data\n",
        "                so that training can be resumed post that checkpoint.\n",
        "\n",
        "        Args:\n",
        "            checkpoint (int, optional): Checkpoint index. Defaults to None.\n",
        "            metadata (dict[str, any], optional): Additional metadata to save alongside a checkpoint. Defaults to None.\n",
        "        \"\"\"\n",
        "\n",
        "        if checkpoint is not None:\n",
        "            checkpoint_dir = os.path.join(self.directory, f\"checkpoint-{checkpoint}\")\n",
        "            os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "            torch.save(self.model.state_dict(), os.path.join(checkpoint_dir, \"model.pt\"))\n",
        "            torch.save(self.optimizer.state_dict(), os.path.join(checkpoint_dir, \"optimizer.pt\"))\n",
        "            with open(os.path.join(checkpoint_dir, \"loss.json\"), \"w+\", encoding='utf-8') as ofile:\n",
        "                json.dump(self.loss_history, ofile, ensure_ascii=False, indent=2)\n",
        "            if metadata:\n",
        "                with open(os.path.join(checkpoint_dir, \"metadata.json\"), \"w+\", encoding='utf-8') as ofile:\n",
        "                    json.dump(metadata, ofile, ensure_ascii=False, indent=2)\n",
        "        else:\n",
        "            torch.save(self.model, os.path.join(self.directory, \"model.pt\"))\n",
        "            with open(os.path.join(self.directory, \"loss.json\"), \"w+\", encoding='utf-8') as ofile:\n",
        "                json.dump(self.loss_history, ofile, ensure_ascii=False, indent=2)\n",
        "            if metadata:\n",
        "                with open(os.path.join(self.directory, \"metadata.json\"), \"w+\", encoding='utf-8') as ofile:\n",
        "                    json.dump(metadata, ofile, ensure_ascii=False, indent=2)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ojRHAENJ7S1I"
      },
      "source": [
        "To test that the trainer works, try training a simple MLP network:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I8Qo2vdo7S1I"
      },
      "outputs": [],
      "source": [
        "X_train = torch.rand((500, 2))                      # (N x 2)\n",
        "X_dev   = torch.rand((20 , 2))                      # (N x 2)\n",
        "\n",
        "Y_train = (X_train[:, 0] - X_train[:, 1])[:, None]  # (N x 1)\n",
        "Y_dev   = (X_dev  [:, 0] - X_dev  [:, 1])[:, None]  # (N x 1)\n",
        "\n",
        "dummy_train_dataset = TensorDataset(X_train, Y_train)\n",
        "dummy_val_dataset   = TensorDataset(X_dev  , Y_dev  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i63ykUv37S1I",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "e3739444e5a8415782f9db32b64378f9",
            "ccc9f4ca8ced4f628d39641423999473",
            "da0278062bcb442c88164751ffcd2f8f",
            "c54790fc62f4407cbf5a987c4f95db99",
            "5544af0fdcb74bc781d91bfadf5aa9f4",
            "edef9af3544d49c1a664a187e00585e8",
            "ef3b20958c0e4572b6e3987b551dbc44",
            "d79c93db485442ab9fbbe9232739603f",
            "17386cff138444a58635d937917b7812",
            "c1b808864c9342988fadac5720b0ff97",
            "883bf5e61558479bbe764495256f7b39"
          ],
          "height": 136
        },
        "outputId": "8ae8e519-654d-4b67-88bb-d932a3c33712"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/500 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e3739444e5a8415782f9db32b64378f9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[>] epoch # 2, batch #50: loss: 0.20194693 | val_loss: 0.20609779\n",
            "[>] epoch # 4, batch #50: loss: 0.16113785 | val_loss: 0.17873703\n",
            "[>] epoch # 6, batch #50: loss: 0.12830834 | val_loss: 0.15390753\n",
            "[>] epoch # 8, batch #50: loss: 0.07801651 | val_loss: 0.12522122\n",
            "[>] epoch #10, batch #50: loss: 0.08638253 | val_loss: 0.09690882\n"
          ]
        }
      ],
      "source": [
        "model = torch.nn.Sequential(\n",
        "    torch.nn.Linear(2, 4),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(4, 1)\n",
        ")\n",
        "\n",
        "loss_fn = torch.nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "trainer = Trainer(\"mlp\", model, loss_fn, optimizer)\n",
        "trainer.train(dummy_train_dataset, dummy_val_dataset, batch_size=10, save_steps=300)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4hvE3VK7S1J"
      },
      "source": [
        "## Seq-2-Seq Modeling with RNNs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q32giBvl7S1J"
      },
      "source": [
        "In this section, you will implement an encoder-decoder network using RNNs, to learn a conditional language model for the task of translating the names to Hindi.\n",
        "\n",
        "You can use any type of RNN for this purpose: `RNN`, `GRU`, `LSTM`, etc. Consult the pytorch documentation for additional information.\n",
        "\n",
        "Additional tips for training:\n",
        "- Use regularization: Dropout, etc.\n",
        "- Use a suitable optimizer, such as Adam.\n",
        "- Format data accordingly before passing it to the trainer, using the helper functions.\n",
        "- Do you need to pad sequences when processing inputs as a batch?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qgJfdMYX7S1K"
      },
      "outputs": [],
      "source": [
        "## ==== BEGIN EVALUATION PORTION\n",
        "\n",
        "class RNNEncoderDecoderLM(torch.nn.Module):\n",
        "    \"\"\" Implements an Encoder-Decoder network, using RNN units. \"\"\"\n",
        "\n",
        "    # Feel free to add additional parameters to __init__\n",
        "    def __init__(self, src_vocab_size, tgt_vocab_size, embd_dims, hidden_size, num_layers=1, dropout=0.1):\n",
        "        \"\"\" Initializes the encoder-decoder network, implemented via RNNs.\n",
        "\n",
        "        Args:\n",
        "            src_vocab_size (int): Source vocabulary size.\n",
        "            tgt_vocab_size (int): Target vocabulary size.\n",
        "            embd_dims (int): Embedding dimensions.\n",
        "            hidden_size (int): Size/Dimensions for the hidden states.\n",
        "        \"\"\"\n",
        "\n",
        "        super(RNNEncoderDecoderLM, self).__init__()\n",
        "\n",
        "        # Dummy parameter to track the model device. Do not modify.\n",
        "        self._dummy_param = torch.nn.Parameter(torch.Tensor(0), requires_grad=False)\n",
        "\n",
        "        # BEGIN CODE : enc-dec-rnn.init\n",
        "\n",
        "        # ADD YOUR CODE HERE\n",
        "\n",
        "\n",
        "\n",
        "        # BEGIN CODE : enc-dec-rnn.init\n",
        "\n",
        "        self.src_emb = torch.nn.Embedding(src_vocab_size, embd_dims)\n",
        "        self.tgt_emb = torch.nn.Embedding(tgt_vocab_size, embd_dims)\n",
        "\n",
        "        # Use GRU for both encoder and decoder\n",
        "        self.enc_rnn = torch.nn.GRU(\n",
        "            input_size=embd_dims,\n",
        "            hidden_size=hidden_size,\n",
        "            num_layers=num_layers,\n",
        "            dropout=dropout if num_layers > 1 else 0.0,\n",
        "            batch_first=True\n",
        "        )\n",
        "\n",
        "        self.dec_rnn = torch.nn.GRU(\n",
        "            input_size=embd_dims,\n",
        "            hidden_size=hidden_size,\n",
        "            num_layers=num_layers,\n",
        "            dropout=dropout if num_layers > 1 else 0.0,\n",
        "            batch_first=True\n",
        "        )\n",
        "\n",
        "        # Project decoder hidden states to target vocabulary space.\n",
        "        self.out_proj = torch.nn.Linear(hidden_size, tgt_vocab_size)\n",
        "\n",
        "\n",
        "        # END CODE\n",
        "\n",
        "\n",
        "    @property\n",
        "    def device(self):\n",
        "        \"\"\" Returns the device the model parameters are on. \"\"\"\n",
        "        return self._dummy_param.device\n",
        "\n",
        "    def forward(self, inputs, decoder_inputs, decoder_hidden_state=None):\n",
        "        \"\"\" Performs a forward pass over the encoder-decoder network.\n",
        "\n",
        "            Accepts inputs for the encoder, inputs for the decoder, and hidden state for\n",
        "                the decoder to continue generation after the given input.\n",
        "\n",
        "        Args:\n",
        "            inputs (torch.Tensor): tensor of shape [batch_size?, max_seq_length]\n",
        "            decoder_inputs (torch.Tensor): tensor of shape [batch_size?, 1]\n",
        "            decoder_hidden_state (any): tensor to represent decoder hidden state from time step T-1.\n",
        "\n",
        "        Returns:\n",
        "            tuple[torch.Tensor, any]: output from the decoder, and associated hidden state for the next step.\n",
        "            Decoder outputs should be log probabilities over the target vocabulary.\n",
        "        \"\"\"\n",
        "\n",
        "        # BEGIN CODE : enc-dec-rnn.forward\n",
        "\n",
        "        # ADD YOUR CODE HERE\n",
        "                # BEGIN CODE : enc-dec-rnn.forward\n",
        "\n",
        "        # BEGIN CODE : enc-dec-rnn.forward\n",
        "\n",
        "\n",
        "        # Encoder: embed source inputs and process using GRU.\n",
        "        x = self.src_emb(inputs)                   # shape: [B, src_seq_len, embd_dims]\n",
        "        _, h_enc = self.enc_rnn(x)                 # h_enc: [num_layers, B, hidden_size]\n",
        "\n",
        "        # Decoder: embed decoder inputs.\n",
        "        y = self.tgt_emb(decoder_inputs)           # shape: [B, dec_seq_len, embd_dims]\n",
        "        if decoder_hidden_state is not None:\n",
        "            out, new_state = self.dec_rnn(y, decoder_hidden_state)\n",
        "        else:\n",
        "            out, new_state = self.dec_rnn(y, h_enc)  # initialize with encoder final hidden state\n",
        "\n",
        "        # Project decoder outputs to vocabulary space.\n",
        "        out = self.out_proj(out)                   # shape: [B, dec_seq_len, tgt_vocab_size]\n",
        "        return out, new_state\n",
        "\n",
        "\n",
        "        # END CODE\n",
        "\n",
        "\n",
        "        # END CODE\n",
        "\n",
        "    def log_probability(self, seq_x, seq_y):\n",
        "        \"\"\" Compute the conditional log probability of seq_y given seq_x, i.e., log P(seq_y | seq_x).\n",
        "\n",
        "        Args:\n",
        "            seq_x (torch.tensor): Input sequence of tokens.\n",
        "            seq_y (torch.tensor): Output sequence of tokens.\n",
        "\n",
        "        Returns:\n",
        "            float: Log probability of seq_y given seq_x\n",
        "        \"\"\"\n",
        "\n",
        "        # BEGIN CODE : enc-dec-rnn.log_probability\n",
        "\n",
        "        # ADD YOUR CODE HERE\n",
        "\n",
        "        # BEGIN CODE : enc-dec-rnn.log_probability\n",
        "\n",
        "        # BEGIN CODE : enc-dec-rnn.log_probability\n",
        "\n",
        "        # Add a batch dimension for the encoder.\n",
        "        x = seq_x.unsqueeze(0)                      # shape: [1, src_seq_len]\n",
        "\n",
        "        # Decoder input: all tokens except the last.\n",
        "        y_in = seq_y[:-1].unsqueeze(0)              # shape: [1, seq_len - 1]\n",
        "        # Target tokens: all tokens except the first.\n",
        "        y_tgt = seq_y[1:]                           # shape: [seq_len - 1]\n",
        "\n",
        "        # Forward pass through the model.\n",
        "        logits, _ = self.forward(x, y_in)           # logits: [1, seq_len - 1, tgt_vocab_size]\n",
        "        log_probs = F.log_softmax(logits.squeeze(0), dim=-1)  # shape: [seq_len - 1, tgt_vocab_size]\n",
        "\n",
        "        # Sum the log probabilities for the correct target tokens.\n",
        "        log_vals = log_probs[range(len(y_tgt)), y_tgt]\n",
        "        return log_vals.sum().item()\n",
        "\n",
        "\n",
        "\n",
        "        # END CODE\n",
        "\n",
        "## ==== END EVALUATION PORTION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djZmH1UT7S1K"
      },
      "source": [
        "To train the above model, implement for training and evaluation steps in the `RNNEncoderDecoderTrainer` class below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "plixWQjn7S1K"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "class RNNEncoderDecoderTrainer(Trainer):\n",
        "    \"\"\" Performs model training for RNN-based Encoder-Decoder models. \"\"\"\n",
        "\n",
        "    def __init__(self, directory, model, criterion, optimizer):\n",
        "        \"\"\" Initializes the trainer. \"\"\"\n",
        "        super(RNNEncoderDecoderTrainer, self).__init__(directory, model, criterion, optimizer)\n",
        "\n",
        "    @staticmethod\n",
        "    def make_dataloader(dataset, shuffle_data=True, batch_size=8, collate_fn=None):\n",
        "        \"\"\" Create a dataloader for a torch Dataset. \"\"\"\n",
        "        # BEGIN CODE : rnn-enc-dec-trainer.make_dataloader\n",
        "\n",
        "        return DataLoader(dataset, batch_size=batch_size, shuffle=shuffle_data, collate_fn=collate_fn)\n",
        "\n",
        "\n",
        "    def train_step(self, x_batch, y_batch):\n",
        "        \"\"\" Performs a step of training, on the training batch. \"\"\"\n",
        "\n",
        "        # Ensure x_batch and y_batch are on the same device as the model.\n",
        "\n",
        "\n",
        "        # Ensure x_batch and y_batch are on the same device as the model.\n",
        "        x_batch = x_batch.to(self.model.device)\n",
        "        y_batch = y_batch.to(self.model.device)\n",
        "\n",
        "        self.model.train()\n",
        "        self.optimizer.zero_grad()\n",
        "\n",
        "        teacher_forcing_ratio = 1  # Adjust this ratio as desired\n",
        "\n",
        "        # x_batch: [B, src_seq_len]\n",
        "        # y_batch: [B, tgt_seq_len]\n",
        "        batch_size, seq_len = y_batch.size()\n",
        "        tgt_vocab_size = self.model.out_proj.out_features\n",
        "\n",
        "        # Tensor to store outputs at each time step (excluding the first token)\n",
        "        outputs = torch.zeros(batch_size, seq_len - 1, tgt_vocab_size, device=self.model.device)\n",
        "\n",
        "        # Initial decoder input is the first token (assumed [BOS]) from y_batch.\n",
        "        input_token = y_batch[:, 0].unsqueeze(1)  # shape: [B, 1]\n",
        "        hidden = None\n",
        "\n",
        "        # Loop over each time step (starting from t=1)\n",
        "        for t in range(1, seq_len):\n",
        "            # Forward pass for one decoding step\n",
        "            output, hidden = self.model(x_batch, input_token, hidden)\n",
        "            # output shape: [B, 1, tgt_vocab_size]\n",
        "            outputs[:, t-1, :] = output.squeeze(1)\n",
        "\n",
        "            # Decide on teacher forcing\n",
        "            teacher_force = (torch.rand(1).item() < teacher_forcing_ratio)\n",
        "            # Get predicted token\n",
        "            top1 = output.argmax(dim=2)  # shape: [B, 1]\n",
        "\n",
        "            # Next input is ground truth if teacher forcing, else the model's prediction.\n",
        "            input_token = y_batch[:, t].unsqueeze(1) if teacher_force else top1\n",
        "\n",
        "        # Reshape outputs and targets for cross-entropy loss\n",
        "        outputs = outputs.contiguous().view(-1, tgt_vocab_size)\n",
        "        target = y_batch[:, 1:].contiguous().view(-1)\n",
        "\n",
        "        loss = self.criterion(outputs, target)\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "        return loss.item()\n",
        "\n",
        "    def eval_step(self, validation_dataloader):\n",
        "        \"\"\" Performs an evaluation step, on the validation dataloader. \"\"\"\n",
        "        # BEGIN CODE : rnn-enc-dec-trainer.eval_step\n",
        "\n",
        "        self.model.eval()\n",
        "        total_loss = 0.0\n",
        "        count = 0\n",
        "        with torch.no_grad():\n",
        "            for x_batch, y_batch in validation_dataloader:\n",
        "                # Move data to the model device.\n",
        "                x_batch = x_batch.to(self.model.device)\n",
        "                y_batch = y_batch.to(self.model.device)\n",
        "\n",
        "                decoder_inputs = y_batch[:, :-1]\n",
        "                target = y_batch[:, 1:]\n",
        "                outputs, _ = self.model(x_batch, decoder_inputs)\n",
        "                B, T, V = outputs.size()\n",
        "                outputs = outputs.contiguous().view(-1, V)\n",
        "                target = target.contiguous().view(-1)\n",
        "                loss = self.criterion(outputs, target)\n",
        "                total_loss += loss.item()\n",
        "                count += 1\n",
        "        return total_loss / count if count > 0 else 0.0\n",
        "\n",
        "        # END CODE\n",
        "\n",
        "## ==== END EVALUATION PORTION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AX2RQOe87S1L"
      },
      "outputs": [],
      "source": [
        "## == BEGIN EVALUATION PORTION\n",
        "\n",
        "# BEGIN CODE : rnn-enc-dec.params\n",
        "\n",
        "# use actual values from your tokenizer\n",
        "rnn_enc_dec_params = {\n",
        "    'src_vocab_size': len(src_tokenizer.get_vocabulary()),\n",
        "    'tgt_vocab_size': len(tgt_tokenizer.get_vocabulary()),\n",
        "    'embd_dims'     : 256,\n",
        "    'hidden_size'   : 768,\n",
        "    'dropout'       : 0.3,\n",
        "    'num_layers'    : 2\n",
        "}\n",
        "\n",
        "# safe padding id (must be within vocab size)\n",
        "rnn_enc_dec_data_params = dict(\n",
        "    src_padding=14,  # usually 0\n",
        "    tgt_padding=14   # usually 0\n",
        ")\n",
        "\n",
        "rnn_enc_dec_training_params = dict(\n",
        "    num_epochs=30,\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    save_steps=1000,\n",
        "    eval_steps=200\n",
        ")\n",
        "\n",
        "# END CODE\n",
        "\n",
        "torch.manual_seed(42)\n",
        "\n",
        "model = RNNEncoderDecoderLM(**rnn_enc_dec_params)\n",
        "\n",
        "# BEGIN CODE : rnn-enc-dec.train\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss(ignore_index=rnn_enc_dec_data_params['tgt_padding'])\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# END CODE\n",
        "\n",
        "trainer = RNNEncoderDecoderTrainer(\n",
        "    os.path.join(DIRECTORY_NAME, \"rnn.enc-dec\"),\n",
        "    model, criterion, optimizer\n",
        ")\n",
        "\n",
        "## == END EVALUATION PORTION\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZGSIuMYP7S1L",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413,
          "referenced_widgets": [
            "b3357e49d2654713a755e4eeacd09674",
            "9ef00b5410fa4cbd8d7252dee6544be6",
            "620036822af04b28b54d16f974636b1a",
            "39e47b7d966c44eabb5a25d892a85a3c",
            "4d10ee56b2e445d9b8fae1667bd5829a",
            "d9ab4b5ecfa148febf2196dbe988273d",
            "c72ed7d9e2aa478db6c5ecddeb15835b",
            "b6ad4374e1f546cf93d89a0b0d704e9a",
            "457fa2b31ff847e0b5e4dd4b280af5e8",
            "46110e09f0a74682a21e804d2b2e839d",
            "5fd3ea20471347ed879da2cbaed0c3c7"
          ]
        },
        "outputId": "c2ae21a8-d25d-4747-ed2f-b8f2e8e53245"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/4230 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b3357e49d2654713a755e4eeacd09674"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[>] epoch # 2, batch # 59: loss: 0.62451148 | val_loss: 0.61424617\n",
            "[>] epoch # 3, batch #118: loss: 0.38430911 | val_loss: 0.29018675\n",
            "[>] epoch # 5, batch # 36: loss: 0.11951818 | val_loss: 0.25073657\n",
            "[>] epoch # 6, batch # 95: loss: 0.09385983 | val_loss: 0.24666768\n",
            "[>] epoch # 8, batch # 13: loss: 0.06485739 | val_loss: 0.25995685\n",
            "[>] epoch # 9, batch # 72: loss: 0.05864455 | val_loss: 0.24076387\n",
            "[>] epoch #10, batch #131: loss: 0.04215436 | val_loss: 0.25511935\n",
            "[>] epoch #12, batch # 49: loss: 0.01475492 | val_loss: 0.26648781\n",
            "[>] epoch #13, batch #108: loss: 0.03862039 | val_loss: 0.27199891\n",
            "[>] epoch #15, batch # 26: loss: 0.04389961 | val_loss: 0.28045336\n",
            "[>] epoch #16, batch # 85: loss: 0.01910135 | val_loss: 0.27224743\n",
            "[>] epoch #18, batch #  3: loss: 0.02399385 | val_loss: 0.28271223\n",
            "[>] epoch #19, batch # 62: loss: 0.04457237 | val_loss: 0.30543659\n",
            "[>] epoch #20, batch #121: loss: 0.08011019 | val_loss: 0.29247662\n",
            "[>] epoch #22, batch # 39: loss: 0.04699055 | val_loss: 0.29708469\n",
            "[>] epoch #23, batch # 98: loss: 0.02407667 | val_loss: 0.30008950\n",
            "[>] epoch #25, batch # 16: loss: 0.04875302 | val_loss: 0.30532525\n",
            "[>] epoch #26, batch # 75: loss: 0.08419191 | val_loss: 0.31441331\n",
            "[>] epoch #27, batch #134: loss: 0.05947314 | val_loss: 0.30911943\n",
            "[>] epoch #29, batch # 52: loss: 0.02001836 | val_loss: 0.29783447\n",
            "[>] epoch #30, batch #111: loss: 0.03575128 | val_loss: 0.30420227\n"
          ]
        }
      ],
      "source": [
        "# Please do not change anything in the following cell.\n",
        "\n",
        "train_dataset      = TokenizerDataset(train_data     , src_tokenizer, tgt_tokenizer, **rnn_enc_dec_data_params)\n",
        "validation_dataset = TokenizerDataset(validation_data, src_tokenizer, tgt_tokenizer, **rnn_enc_dec_data_params)\n",
        "\n",
        "rnn_enc_dec_train_data = dict(\n",
        "    train_dataset=train_dataset,\n",
        "    validation_dataset=validation_dataset,\n",
        "    collate_fn=train_dataset.collate\n",
        ")\n",
        "\n",
        "# Resume training from the last checkpoint, if interrupted midway, else begins training from scratch.\n",
        "#trainer.resume()\n",
        "\n",
        "# Train as per specified training parameters.\n",
        "trainer.train(**rnn_enc_dec_train_data, **rnn_enc_dec_training_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GtcTRlgs7S1M"
      },
      "outputs": [],
      "source": [
        "# Please do not change anything in the following cell.\n",
        "\n",
        "# Save the final model, with additional metadata.\n",
        "trainer.save(metadata={\n",
        "    'model'   : rnn_enc_dec_params,\n",
        "    'data'    : rnn_enc_dec_data_params,\n",
        "    'training': rnn_enc_dec_training_params\n",
        "})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUshh3Uv7S1N"
      },
      "source": [
        "To validate training, look at sample translations for different examples, and probabilities assigned to different outputs.\n",
        "\n",
        "Extensive evaluation and comparison against other approaches will be carried out later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "USVATGO17S1O"
      },
      "outputs": [],
      "source": [
        "def rnn_greedy_generate(model, seq_x, src_tokenizer, tgt_tokenizer, max_length):\n",
        "    \"\"\" Given a source string, translate it to the target language using the trained model.\n",
        "        This function performs greedy sampling to generate the results.\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): RNN Type Encoder-Decoder Model.\n",
        "        seq_x (str): Input string to translate.\n",
        "        src_tokenizer (Tokenizer): Source language tokenizer.\n",
        "        tgt_tokenizer (Tokenizer): Target language tokenizer.\n",
        "        max_length (int): Maximum length of the target sequence to decode.\n",
        "\n",
        "    Returns:\n",
        "        str: Generated string for the given input in the target language.\n",
        "    \"\"\"\n",
        "\n",
        "    # BEGIN CODE : enc-dec-rnn.greedy_generate\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        # 1) Convert the source string to tensor and move to model's device.\n",
        "        src_ids = [src_tokenizer.encode(seq_x)]\n",
        "        src_tensor = torch.tensor(src_ids, device=model.device)\n",
        "\n",
        "        # 2) Retrieve BOS/EOS token IDs from the target tokenizer.\n",
        "        bos_token = tgt_tokenizer.get_special_tokens()['[BOS]']\n",
        "        eos_token = tgt_tokenizer.get_special_tokens()['[EOS]']\n",
        "\n",
        "        # 3) Prime the model: run the encoder with a single BOS token.\n",
        "        bos_tensor = torch.tensor([[bos_token]], device=model.device)\n",
        "        logits, hidden = model(src_tensor, bos_tensor, decoder_hidden_state=None)\n",
        "\n",
        "        # 4) Capture the first predicted token (so it isn’t dropped)\n",
        "        first_token_id = logits[:, -1, :].argmax(dim=-1).item()\n",
        "        generated = []\n",
        "        if first_token_id != eos_token:\n",
        "            generated.append(first_token_id)\n",
        "\n",
        "        # 5) Continue decoding step-by-step\n",
        "        next_input = torch.tensor([[first_token_id]], device=model.device)\n",
        "        for _ in range(max_length - 1):\n",
        "            logits, hidden = model(src_tensor, next_input, hidden)\n",
        "            next_token_id = logits[:, -1, :].argmax(dim=-1).item()\n",
        "            if next_token_id == eos_token:\n",
        "                break\n",
        "            generated.append(next_token_id)\n",
        "            next_input = torch.tensor([[next_token_id]], device=model.device)\n",
        "\n",
        "        # 6) Convert token IDs back to string.\n",
        "        return tgt_tokenizer.decode(generated)\n",
        "\n",
        "    # END CODE\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tz4Ud06A7S1O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a9eb230-8a6d-441c-8c67-5f80388b148f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name                      : वरिषा\n",
            "Translation (Expected)    : varisha\n",
            "Translation (Model)       : varisha\n",
            "\n",
            "Name                      : उजामा\n",
            "Translation (Expected)    : ujama\n",
            "Translation (Model)       : ujama\n",
            "\n",
            "Name                      : बिपिन\n",
            "Translation (Expected)    : bipin\n",
            "Translation (Model)       : bipin\n",
            "\n",
            "Name                      : मित्ठू\n",
            "Translation (Expected)    : mitthu\n",
            "Translation (Model)       : mitthu\n",
            "\n",
            "Name                      : रामैया\n",
            "Translation (Expected)    : ramaiya\n",
            "Translation (Model)       : ramaiya\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Please do not change anything in the following cell.\n",
        "\n",
        "for _, row in train_data.sample(n=5, random_state=42).iterrows():\n",
        "    y_pred = rnn_greedy_generate(\n",
        "        model, row['Name'], src_tokenizer, tgt_tokenizer,\n",
        "        max_length = rnn_enc_dec_data_params['tgt_padding']\n",
        "    )\n",
        "\n",
        "    print(\"Name                      :\", row['Name'])\n",
        "    print(\"Translation (Expected)    :\", row['Translation'])\n",
        "    print(\"Translation (Model)       :\", y_pred)\n",
        "\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FvEL5aYR7S1O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5dde57f7-610a-4c44-e5c7-65c9aa56dc33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name                      : दीन\n",
            "Translation (Expected)    : deen\n",
            "Translation (Model)       : deen\n",
            "\n",
            "Name                      : मुर्शिदा\n",
            "Translation (Expected)    : murshida\n",
            "Translation (Model)       : mursida\n",
            "\n",
            "Name                      : शबरा\n",
            "Translation (Expected)    : shabra\n",
            "Translation (Model)       : shabra\n",
            "\n",
            "Name                      : श्रीकांत\n",
            "Translation (Expected)    : shrikant\n",
            "Translation (Model)       : srikant\n",
            "\n",
            "Name                      : कौशल\n",
            "Translation (Expected)    : kaushal\n",
            "Translation (Model)       : kaushal\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Please do not change anything in the following cell.\n",
        "\n",
        "for _, row in validation_data.sample(n=5, random_state=42).iterrows():\n",
        "    y_pred = rnn_greedy_generate(\n",
        "        model, row['Name'], src_tokenizer, tgt_tokenizer,\n",
        "        max_length = rnn_enc_dec_data_params['tgt_padding']\n",
        "    )\n",
        "\n",
        "    print(\"Name                      :\", row['Name'])\n",
        "    print(\"Translation (Expected)    :\", row['Translation'])\n",
        "    print(\"Translation (Model)       :\", y_pred)\n",
        "\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GaoL9IUrsaFU"
      },
      "outputs": [],
      "source": [
        "# Please do not change anything in the following cell.\n",
        "\n",
        "output_data = []\n",
        "for _, row in validation_data.iterrows():\n",
        "    y_pred = rnn_greedy_generate(\n",
        "        model, row['Name'], src_tokenizer, tgt_tokenizer,\n",
        "        max_length = rnn_enc_dec_data_params['tgt_padding']\n",
        "    )\n",
        "    output_data.append({ 'Name': row['Name'], 'Translation': y_pred })\n",
        "\n",
        "pd.DataFrame.from_records(output_data).to_csv(\n",
        "    os.path.join(DIRECTORY_NAME, \"rnn.enc-dec\", \"outputs.csv\"), index=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-XRDFy1U7S1P"
      },
      "outputs": [],
      "source": [
        "# Please do not change anything in the following cell.\n",
        "\n",
        "# Release resources\n",
        "if 'trainer' in globals():\n",
        "    del trainer\n",
        "\n",
        "if 'model' in globals():\n",
        "    del model\n",
        "\n",
        "sync_vram()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gkAB3ivx7S1Q"
      },
      "source": [
        "## Seq-2-Seq Modeling with RNN + Attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPpFw0Fn7S1Q"
      },
      "source": [
        "In this module, you'll augment the Encoder-Decoder architecture to utilize attention, by implementing an Attention module that attends over the representations / inputs from the encoder.\n",
        "\n",
        "Many approaches have been proposed in literature towards implementing attention. You are free to explore and use any implementation of your choice.\n",
        "\n",
        "Some popular approaches are desribed in the original [paper by Bahdanau et al., 2014 on NMT](https://arxiv.org/abs/1409.0473) and an [exploratory paper by Luong et al, 2015](https://arxiv.org/abs/1508.04025) which explores different effective approaches to attention, including global and local attention."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l2wmAoC77S1R"
      },
      "outputs": [],
      "source": [
        "## ==== BEGIN EVALUATION PORTION\n",
        "\n",
        "class AttentionModule(torch.nn.Module):\n",
        "    \"\"\" Implements an attention module \"\"\"\n",
        "\n",
        "    # Feel free to add additional parameters to __init__\n",
        "    def __init__(self, input_size):\n",
        "        \"\"\" Initializes the attention module.\n",
        "            Feel free to declare any parameters as required. \"\"\"\n",
        "\n",
        "        super(AttentionModule, self).__init__()\n",
        "\n",
        "        # BEGIN CODE : attn.init\n",
        "\n",
        "        # ADD YOUR CODE HERE\n",
        "        # Here, input_size is the hidden dimension.\n",
        "        # We concatenate the decoder hidden state and each encoder output (each of size input_size),\n",
        "        # so we have 2*input_size. Then, we project this concatenated vector to a single energy value.\n",
        "        self.attn = torch.nn.Linear(input_size * 2, input_size)\n",
        "        self.v = torch.nn.Linear(input_size, 1, bias=False)\n",
        "\n",
        "\n",
        "        # END CODE\n",
        "\n",
        "    def forward(self, encoder_outputs, decoder_hidden_state):\n",
        "        \"\"\" Performs a forward pass over the module, computing attention scores for inputs.\n",
        "\n",
        "        Args:\n",
        "            encoder_outputs (torch.Tensor): Output representations from the encoder, of shape [batch_size?, src_seq_len, output_dim].\n",
        "            decoder_hidden_state (torch.Tensor): Hidden state from the decoder at current time step, of appropriate shape as per RNN unit (with optional batch dim).\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Attentions scores for given inputs, of shape [batch_size?, 1, src_seq_len]\n",
        "        \"\"\"\n",
        "\n",
        "        # BEGIN CODE : attn.forward\n",
        "\n",
        "        # ADD YOUR CODE HERE\n",
        "        # Repeat decoder_hidden_state for each time step\n",
        "        batch_size, src_len, hidden_size = encoder_outputs.size()\n",
        "        decoder_hidden = decoder_hidden_state.unsqueeze(1).repeat(1, src_len, 1)  # [B, src_len, hidden_size]\n",
        "        # Concatenate decoder hidden state with encoder outputs and compute energy\n",
        "        energy = torch.tanh(self.attn(torch.cat((decoder_hidden, encoder_outputs), dim=2)))  # [B, src_len, hidden_size]\n",
        "        # Project energy to a scalar and squeeze out the last dimension\n",
        "        attention_scores = self.v(energy).squeeze(2)  # [B, src_len]\n",
        "        # Apply softmax to get attention weights\n",
        "        attn_weights = torch.softmax(attention_scores, dim=1)  # [B, src_len]\n",
        "        # Reshape to [B, 1, src_len]\n",
        "        return attn_weights.unsqueeze(1)\n",
        "\n",
        "        # END CODE\n",
        "\n",
        "## ==== END EVALUATION PORTION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8q73WPlp7S1R"
      },
      "outputs": [],
      "source": [
        "## ==== BEGIN EVALUATION PORTION\n",
        "\n",
        "class RNNEncoderDecoderLMWithAttention(torch.nn.Module):\n",
        "    \"\"\" Implements an Encoder-Decoder network, using RNN units, augmented with attention. \"\"\"\n",
        "\n",
        "    # Feel free to add additional parameters to __init__\n",
        "    def __init__(self,src_vocab_size, tgt_vocab_size, embd_dims, hidden_size, num_layers=1, dropout=0.1):\n",
        "        \"\"\" Initializes the encoder-decoder network, implemented via RNNs.\n",
        "\n",
        "        Args:\n",
        "            src_vocab_size (int): Source vocabulary size.\n",
        "            tgt_vocab_size (int): Target vocabulary size.\n",
        "            embd_dims (int): Embedding dimensions.\n",
        "            hidden_size (int): Size/Dimensions for the hidden states.\n",
        "        \"\"\"\n",
        "\n",
        "        super(RNNEncoderDecoderLMWithAttention, self).__init__()\n",
        "\n",
        "        # Dummy parameter to track the model device. Do not modify.\n",
        "        self._dummy_param = torch.nn.Parameter(torch.Tensor(0), requires_grad=False)\n",
        "\n",
        "        # BEGIN CODE : enc-dec-rnn-attn.init\n",
        "\n",
        "        # ADD YOUR CODE HERE\n",
        "        self.src_emb = torch.nn.Embedding(src_vocab_size, embd_dims)\n",
        "        self.tgt_emb = torch.nn.Embedding(tgt_vocab_size, embd_dims)\n",
        "\n",
        "        # Encoder GRU\n",
        "        self.enc_rnn = torch.nn.GRU(\n",
        "            input_size=embd_dims,\n",
        "            hidden_size=hidden_size,\n",
        "            num_layers=num_layers,\n",
        "            dropout=dropout if num_layers > 1 else 0.0,\n",
        "            batch_first=True\n",
        "        )\n",
        "\n",
        "        # Decoder GRU\n",
        "        self.dec_rnn = torch.nn.GRU(\n",
        "            input_size=embd_dims,\n",
        "            hidden_size=hidden_size,\n",
        "            num_layers=num_layers,\n",
        "            dropout=dropout if num_layers > 1 else 0.0,\n",
        "            batch_first=True\n",
        "        )\n",
        "\n",
        "        # Attention module\n",
        "        self.attention_module = AttentionModule(hidden_size)\n",
        "\n",
        "        # Final projection: after concatenating decoder output and context (2*hidden_size)\n",
        "        self.out_proj = torch.nn.Linear(hidden_size * 2, tgt_vocab_size)\n",
        "\n",
        "        # END CODE\n",
        "\n",
        "    @property\n",
        "    def device(self):\n",
        "        return self._dummy_param.device\n",
        "\n",
        "    def log_probability(self, seq_x, seq_y):\n",
        "        \"\"\" Compute the conditional log probability of seq_y given seq_x, i.e., log P(seq_y | seq_x).\n",
        "\n",
        "        Args:\n",
        "            seq_x (torch.tensor): Input sequence of tokens, of shape [src_seq_len] (no batch dim)\n",
        "            seq_y (torch.tensor): Output sequence of tokens, of shape [tgt_seq_len] (no batch dim)\n",
        "\n",
        "        Returns:\n",
        "            float: Log probability of generating sequence y, given sequence x.\n",
        "        \"\"\"\n",
        "\n",
        "        # BEGIN CODE : enc-dec-rnn-attn.probability\n",
        "\n",
        "        # ADD YOUR CODE HERE\n",
        "        # Add batch dimension\n",
        "        x = seq_x.unsqueeze(0)  # [1, src_seq_len]\n",
        "        # Use all tokens except the last as decoder input\n",
        "        y_in = seq_y[:-1].unsqueeze(0)  # [1, tgt_seq_len-1]\n",
        "        # Target tokens are all tokens except the first\n",
        "        y_target = seq_y[1:]  # [tgt_seq_len-1]\n",
        "        # Forward pass\n",
        "        logits, _ = self.forward(x, y_in)  # logits: [1, tgt_seq_len-1, tgt_vocab_size]\n",
        "        log_probs = torch.log_softmax(logits.squeeze(0), dim=-1)  # [tgt_seq_len-1, tgt_vocab_size]\n",
        "        log_vals = log_probs[range(len(y_target)), y_target]\n",
        "        return log_vals.sum().item()\n",
        "\n",
        "        # END CODE\n",
        "\n",
        "    def attentions(self, seq_x, terminate_token, max_length):\n",
        "        \"\"\" Obtain attention over a sequence for decoding to the target language.\n",
        "\n",
        "        Args:\n",
        "            seq_x (torch.tensor): Tensor representing the source sequence, of shape [src_seq_len] (no batch dim)\n",
        "            terminate_token (int): Token to use as EOS, to stop generating outputs.\n",
        "            max_length (int): Maximum length to use to terminate the sampling.\n",
        "\n",
        "        Returns:\n",
        "            tuple[torch.tensor, torch.tensor]:\n",
        "                A tuple of two tensors: the attentions over individual output tokens ([tgt_seq_len, src_seq_len])\n",
        "                and the best output tokens ([tgt_seq_len]) per sequence step, based on greedy sampling.\n",
        "        \"\"\"\n",
        "\n",
        "        # BEGIN CODE : rnn-enc-dec-attn.attentions\n",
        "\n",
        "        # ADD YOUR CODE HERE\n",
        "\n",
        "        self.eval()\n",
        "        with torch.no_grad():\n",
        "            # Add batch dimension to source\n",
        "            x = seq_x.to(self.device).unsqueeze(0)  # [1, src_seq_len]\n",
        "            # Encoder: embed and run through GRU\n",
        "            encoder_emb = self.src_emb(x)  # [1, src_seq_len, embd_dims]\n",
        "            encoder_outputs, h_enc = self.enc_rnn(encoder_emb)  # encoder_outputs: [1, src_seq_len, hidden_size]\n",
        "            # Initialize decoder hidden state with encoder final state\n",
        "            hidden = h_enc\n",
        "            # Assume [BOS] token is 1 (as per tokenizer)\n",
        "            bos_token = 1\n",
        "            current_input = torch.tensor([[bos_token]], device=self.device)  # [1, 1]\n",
        "            attn_list = []\n",
        "            output_tokens = []\n",
        "            for _ in range(max_length):\n",
        "                dec_emb = self.tgt_emb(current_input)  # [1, 1, embd_dims]\n",
        "                dec_output, hidden = self.dec_rnn(dec_emb, hidden)  # dec_output: [1, 1, hidden_size]\n",
        "                # Compute attention using the last layer's hidden state\n",
        "                attn_weights = self.attention_module(encoder_outputs, hidden[-1])  # [1, 1, src_seq_len]\n",
        "                attn_list.append(attn_weights.squeeze(0))  # [1, src_seq_len] -> [src_seq_len]\n",
        "                # Compute context vector as weighted sum of encoder outputs\n",
        "                context = torch.bmm(attn_weights, encoder_outputs)  # [1, 1, hidden_size]\n",
        "                # Combine decoder output and context\n",
        "                combined = torch.cat((dec_output, context), dim=2)  # [1, 1, hidden_size*2]\n",
        "                combined = torch.tanh(combined)\n",
        "                token_logits = self.out_proj(combined.squeeze(1))  # [1, tgt_vocab_size]\n",
        "                next_token = token_logits.argmax(dim=-1).item()\n",
        "                output_tokens.append(next_token)\n",
        "                if next_token == terminate_token:\n",
        "                    break\n",
        "                current_input = torch.tensor([[next_token]], device=self.device)\n",
        "            # Stack attention weights: list of [src_seq_len] tensors to [tgt_seq_len, src_seq_len]\n",
        "\n",
        "\n",
        "            # After stacking and optionally squeezing attention weights:\n",
        "            attn_tensor = torch.stack(attn_list, dim=0)  # shape: [tgt_seq_len, 1, src_seq_len]\n",
        "            if attn_tensor.ndim == 3 and attn_tensor.shape[1] == 1:\n",
        "                attn_tensor = attn_tensor.squeeze(1)  # shape: [tgt_seq_len, src_seq_len]\n",
        "            output_tokens = torch.tensor(output_tokens)\n",
        "            # Move attention tensor to CPU\n",
        "            attn_tensor = attn_tensor.cpu()\n",
        "            output_tokens = output_tokens.cpu()\n",
        "            return attn_tensor, output_tokens\n",
        "\n",
        "\n",
        "\n",
        "        # END CODE\n",
        "\n",
        "    def forward(self, inputs, decoder_inputs=None, decoder_hidden_state=None, output_attention=False):\n",
        "        \"\"\" Performs a forward pass over the encoder-decoder network.\n",
        "\n",
        "            Accepts inputs for the encoder, inputs for the decoder, and hidden state for\n",
        "                the decoder to continue generation after the given input.\n",
        "\n",
        "        Args:\n",
        "            inputs (torch.Tensor): tensor of shape [batch_size?, src_seq_len]\n",
        "            decoder_inputs (torch.Tensor): Decoder inputs, as tensor of shape [batch_size?, 1]\n",
        "            decoder_hidden_state (any): tensor to represent decoder hidden state from time step T-1.\n",
        "            output_attention (bool): If true, this function should also return the\n",
        "                associated attention weights for the time step, of shape [batch_size?, 1, src_seq_len].\n",
        "\n",
        "        Returns:\n",
        "            tuple[torch.Tensor, any]: output from the decoder, and associated hidden state for the next step.\n",
        "\n",
        "            Decoder outputs should be log probabilities over the target vocabulary.\n",
        "\n",
        "        Example:\n",
        "        >>> model = RNNEncoderDecoderWithAttention(*args, **kwargs)\n",
        "        >>> output, hidden = model(..., output_attention=False)\n",
        "        >>> output, hidden, attn_weights = model(..., output_attention=True)\n",
        "        \"\"\"\n",
        "\n",
        "        # BEGIN CODE : enc-dec-rnn-attn.forward\n",
        "\n",
        "        # ADD YOUR CODE HERE\n",
        "\n",
        "        inputs = inputs.to(self.device)\n",
        "        if decoder_inputs is not None:\n",
        "            decoder_inputs = decoder_inputs.to(self.device)\n",
        "        # ... rest of your code\n",
        "\n",
        "        # Encoder pass\n",
        "        x = self.src_emb(inputs)  # [B, src_seq_len, embd_dims]\n",
        "        encoder_outputs, h_enc = self.enc_rnn(x)  # encoder_outputs: [B, src_seq_len, hidden_size]\n",
        "        if decoder_hidden_state is None:\n",
        "            decoder_hidden_state = h_enc\n",
        "        # If decoder_inputs is provided, do step-by-step decoding with attention.\n",
        "        if decoder_inputs is not None:\n",
        "            B, T = decoder_inputs.size()\n",
        "            outputs = []\n",
        "            attn_weights_list = [] if output_attention else None\n",
        "            hidden = decoder_hidden_state\n",
        "            for t in range(T):\n",
        "                current_input = decoder_inputs[:, t].unsqueeze(1)  # [B, 1]\n",
        "                dec_emb = self.tgt_emb(current_input)  # [B, 1, embd_dims]\n",
        "                dec_output, hidden = self.dec_rnn(dec_emb, hidden)  # [B, 1, hidden_size]\n",
        "                # Compute attention using last layer hidden state: [B, hidden_size]\n",
        "                attn_weights = self.attention_module(encoder_outputs, hidden[-1])  # [B, 1, src_seq_len]\n",
        "                if output_attention:\n",
        "                    attn_weights_list.append(attn_weights)\n",
        "                # Compute context vector\n",
        "                context = torch.bmm(attn_weights, encoder_outputs)  # [B, 1, hidden_size]\n",
        "                # Concatenate decoder output and context\n",
        "                combined = torch.cat((dec_output, context), dim=2)  # [B, 1, hidden_size*2]\n",
        "                combined = torch.tanh(combined)\n",
        "                token_logits = self.out_proj(combined.squeeze(1))  # [B, tgt_vocab_size]\n",
        "                outputs.append(token_logits.unsqueeze(1))  # [B, 1, tgt_vocab_size]\n",
        "            outputs = torch.cat(outputs, dim=1)  # [B, T, tgt_vocab_size]\n",
        "            if output_attention:\n",
        "                # Concatenate attention weights along time dimension: each is [B, 1, src_seq_len]\n",
        "                attn_all = torch.cat(attn_weights_list, dim=1)  # [B, T, src_seq_len]\n",
        "                return outputs, hidden, attn_all\n",
        "            return outputs, hidden\n",
        "        else:\n",
        "            # If no decoder_inputs, return encoder outputs and hidden state.\n",
        "            return encoder_outputs, h_enc\n",
        "\n",
        "        # END CODE\n",
        "\n",
        "## ==== END EVALUATION PORTION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cuLUZV167S1S"
      },
      "outputs": [],
      "source": [
        "## == BEGIN EVALUATION PORTION\n",
        "\n",
        "# Edit the hyperparameters below to your desired values.\n",
        "\n",
        "# BEGIN CODE : rnn-enc-dec-attn.params\n",
        "\n",
        "# Add parameters related to the model here.\n",
        "# BEGIN CODE : rnn-enc-dec-attn.params\n",
        "rnn_enc_dec_attn_params = {\n",
        "    'src_vocab_size': len(src_tokenizer.get_vocabulary()),\n",
        "    'tgt_vocab_size': len(tgt_tokenizer.get_vocabulary()),\n",
        "    'embd_dims'     : 384, #256,\n",
        "    'hidden_size'   : 768,\n",
        "    'dropout'       : 0.3,\n",
        "    'num_layers'    : 2\n",
        "}\n",
        "\n",
        "rnn_enc_dec_attn_data_params = dict(\n",
        "    src_padding=14,  # adjust as needed\n",
        "    tgt_padding=14\n",
        ")\n",
        "\n",
        "rnn_enc_dec_attn_training_params = dict(\n",
        "    num_epochs=30,\n",
        "    batch_size=16,      #32, 64 giving more than 128\n",
        "    shuffle=True,\n",
        "    save_steps=1000,\n",
        "    eval_steps=200\n",
        ")\n",
        "# END CODE\n",
        "\n",
        "\n",
        "# END CODE\n",
        "\n",
        "# Do not forget to set a deterministic seed.\n",
        "torch.manual_seed(42)\n",
        "\n",
        "model = RNNEncoderDecoderLMWithAttention(**rnn_enc_dec_attn_params)\n",
        "\n",
        "# BEGIN CODE : rnn-enc-dec-attn.train\n",
        "\n",
        "# ADD YOUR CODE HERE\n",
        "# BEGIN CODE : rnn-enc-dec-attn.train\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss(ignore_index=rnn_enc_dec_attn_data_params['tgt_padding'])\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# END CODE\n",
        "\n",
        "# END CODE\n",
        "\n",
        "trainer = RNNEncoderDecoderTrainer(\n",
        "    os.path.join(DIRECTORY_NAME, \"rnn.enc-dec.attn\"),\n",
        "    model, criterion, optimizer\n",
        ")\n",
        "\n",
        "## == END EVALUATION PORTION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H_oypGhq7S1S",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 778,
          "referenced_widgets": [
            "880f59f092474eb78bb147e00bbe62ed",
            "ceef0d49d744492487951bd016cdfdcc",
            "2d512b1578924f9a84c1d7e5352c701c",
            "f7f1c812167e4a8fbd38800585052e7d",
            "44324d2c672646d8af506ed9b3e9dc1e",
            "522cc2279ba0421292f1a76a49e528bc",
            "f15a4b62faab43d5a5b9e3d5520d5dbc",
            "93fe5e61a67441d3923a9426b959e9a5",
            "13cd038ec5c6403f9a268964529ebbb1",
            "6ec9926dd96b46679b6fd9efd0ab3471",
            "91a82428b3254159b8a6a156f8f020fc"
          ]
        },
        "outputId": "8c0f9744-09af-4536-ee71-49db9ea1305a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/8430 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "880f59f092474eb78bb147e00bbe62ed"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[>] epoch # 1, batch #200: loss: 0.57164955 | val_loss: 0.50594366\n",
            "[>] epoch # 2, batch #119: loss: 0.23230515 | val_loss: 0.27560227\n",
            "[>] epoch # 3, batch # 38: loss: 0.19549546 | val_loss: 0.23754961\n",
            "[>] epoch # 3, batch #238: loss: 0.19035117 | val_loss: 0.23036562\n",
            "[>] epoch # 4, batch #157: loss: 0.11947723 | val_loss: 0.22556226\n",
            "[>] epoch # 5, batch # 76: loss: 0.06205313 | val_loss: 0.21670613\n",
            "[>] epoch # 5, batch #276: loss: 0.10424708 | val_loss: 0.22815119\n",
            "[>] epoch # 6, batch #195: loss: 0.13813461 | val_loss: 0.22916625\n",
            "[>] epoch # 7, batch #114: loss: 0.06491795 | val_loss: 0.21374508\n",
            "[>] epoch # 8, batch # 33: loss: 0.05826622 | val_loss: 0.24485689\n",
            "[>] epoch # 8, batch #233: loss: 0.06686439 | val_loss: 0.24250043\n",
            "[>] epoch # 9, batch #152: loss: 0.07181190 | val_loss: 0.23894663\n",
            "[>] epoch #10, batch # 71: loss: 0.01985207 | val_loss: 0.24944788\n",
            "[>] epoch #10, batch #271: loss: 0.05796881 | val_loss: 0.29043711\n",
            "[>] epoch #11, batch #190: loss: 0.08449200 | val_loss: 0.27190763\n",
            "[>] epoch #12, batch #109: loss: 0.02735491 | val_loss: 0.27426909\n",
            "[>] epoch #13, batch # 28: loss: 0.06007551 | val_loss: 0.27825689\n",
            "[>] epoch #13, batch #228: loss: 0.10168813 | val_loss: 0.27661797\n",
            "[>] epoch #14, batch #147: loss: 0.02230659 | val_loss: 0.29727374\n",
            "[>] epoch #15, batch # 66: loss: 0.01739834 | val_loss: 0.28119849\n",
            "[>] epoch #15, batch #266: loss: 0.12798674 | val_loss: 0.29471900\n",
            "[>] epoch #16, batch #185: loss: 0.01138373 | val_loss: 0.28084854\n",
            "[>] epoch #17, batch #104: loss: 0.06688008 | val_loss: 0.28883667\n",
            "[>] epoch #18, batch # 23: loss: 0.02848486 | val_loss: 0.29165772\n",
            "[>] epoch #18, batch #223: loss: 0.08078040 | val_loss: 0.28248863\n",
            "[>] epoch #19, batch #142: loss: 0.02956449 | val_loss: 0.28140953\n",
            "[>] epoch #20, batch # 61: loss: 0.05303872 | val_loss: 0.28090649\n",
            "[>] epoch #20, batch #261: loss: 0.06499743 | val_loss: 0.29112319\n",
            "[>] epoch #21, batch #180: loss: 0.05534017 | val_loss: 0.28535689\n",
            "[>] epoch #22, batch # 99: loss: 0.04662360 | val_loss: 0.28886147\n",
            "[>] epoch #23, batch # 18: loss: 0.02094553 | val_loss: 0.30407758\n",
            "[>] epoch #23, batch #218: loss: 0.09131401 | val_loss: 0.29295323\n",
            "[>] epoch #24, batch #137: loss: 0.00939980 | val_loss: 0.29493055\n",
            "[>] epoch #25, batch # 56: loss: 0.05793935 | val_loss: 0.29411292\n",
            "[>] epoch #25, batch #256: loss: 0.03099585 | val_loss: 0.30332351\n",
            "[>] epoch #26, batch #175: loss: 0.04018970 | val_loss: 0.29261456\n",
            "[>] epoch #27, batch # 94: loss: 0.06508727 | val_loss: 0.30406356\n",
            "[>] epoch #28, batch # 13: loss: 0.04648720 | val_loss: 0.30475865\n",
            "[>] epoch #28, batch #213: loss: 0.15051505 | val_loss: 0.30423644\n",
            "[>] epoch #29, batch #132: loss: 0.06347915 | val_loss: 0.31330098\n",
            "[>] epoch #30, batch # 51: loss: 0.00530497 | val_loss: 0.30681149\n",
            "[>] epoch #30, batch #251: loss: 0.07411881 | val_loss: 0.32728023\n"
          ]
        }
      ],
      "source": [
        "# Please do not change anything in the following cell.\n",
        "\n",
        "train_dataset      = TokenizerDataset(train_data     , src_tokenizer, tgt_tokenizer, **rnn_enc_dec_attn_data_params)\n",
        "validation_dataset = TokenizerDataset(validation_data, src_tokenizer, tgt_tokenizer, **rnn_enc_dec_attn_data_params)\n",
        "\n",
        "rnn_enc_dec_attn_train_data = dict(\n",
        "    train_dataset=train_dataset,\n",
        "    validation_dataset=validation_dataset,\n",
        "    collate_fn=train_dataset.collate\n",
        ")\n",
        "\n",
        "# Resume training from the last checkpoint, if interrupted midway, otherwise starts from scratch.\n",
        "#trainer.resume()\n",
        "\n",
        "# Train as per specified training parameters.\n",
        "trainer.train(**rnn_enc_dec_attn_train_data, **rnn_enc_dec_attn_training_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bAYwB5i47S1T"
      },
      "outputs": [],
      "source": [
        "# Please do not change anything in the following cell.\n",
        "\n",
        "# Save the final model, with additional metadata.\n",
        "trainer.save(metadata={\n",
        "    'model'   : rnn_enc_dec_attn_params,\n",
        "    'data'    : rnn_enc_dec_attn_data_params,\n",
        "    'training': rnn_enc_dec_attn_training_params\n",
        "})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0qIb8Qkg7S1T"
      },
      "source": [
        "We can validate the model using a few simple tests as below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f1RKp9rM7S1T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a72dbc5-91e2-42ef-aea1-09068dba548d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name                      : वरिषा\n",
            "Translation (Expected)    : varisha\n",
            "Translation (Model)       : varisha\n",
            "\n",
            "Name                      : उजामा\n",
            "Translation (Expected)    : ujama\n",
            "Translation (Model)       : ujama\n",
            "\n",
            "Name                      : बिपिन\n",
            "Translation (Expected)    : bipin\n",
            "Translation (Model)       : binin\n",
            "\n",
            "Name                      : मित्ठू\n",
            "Translation (Expected)    : mitthu\n",
            "Translation (Model)       : mitthu\n",
            "\n",
            "Name                      : रामैया\n",
            "Translation (Expected)    : ramaiya\n",
            "Translation (Model)       : ramaiya\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Please do not change anything in the following cell.\n",
        "\n",
        "for _, row in train_data.sample(n=5, random_state=42).iterrows():\n",
        "    y_pred = rnn_greedy_generate(\n",
        "        model, row['Name'], src_tokenizer, tgt_tokenizer,\n",
        "        max_length = rnn_enc_dec_attn_data_params['tgt_padding']\n",
        "    )\n",
        "\n",
        "    print(\"Name                      :\", row['Name'])\n",
        "    print(\"Translation (Expected)    :\", row['Translation'])\n",
        "    print(\"Translation (Model)       :\", y_pred)\n",
        "\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rt6MLKYX7S1U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5eb34e8a-d567-4a54-f3e5-18f9c0437976"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name                      : दीन\n",
            "Translation (Expected)    : deen\n",
            "Translation (Model)       : deen\n",
            "\n",
            "Name                      : मुर्शिदा\n",
            "Translation (Expected)    : murshida\n",
            "Translation (Model)       : mursida\n",
            "\n",
            "Name                      : शबरा\n",
            "Translation (Expected)    : shabra\n",
            "Translation (Model)       : shabra\n",
            "\n",
            "Name                      : श्रीकांत\n",
            "Translation (Expected)    : shrikant\n",
            "Translation (Model)       : shrikant\n",
            "\n",
            "Name                      : कौशल\n",
            "Translation (Expected)    : kaushal\n",
            "Translation (Model)       : kaushal\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Please do not change anything in the following cell.\n",
        "\n",
        "for _, row in validation_data.sample(n=5, random_state=42).iterrows():\n",
        "    y_pred = rnn_greedy_generate(\n",
        "        model, row['Name'], src_tokenizer, tgt_tokenizer,\n",
        "        max_length = rnn_enc_dec_attn_data_params['tgt_padding']\n",
        "    )\n",
        "\n",
        "    print(\"Name                      :\", row['Name'])\n",
        "    print(\"Translation (Expected)    :\", row['Translation'])\n",
        "    print(\"Translation (Model)       :\", y_pred)\n",
        "\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i8BHmGBR7S1U"
      },
      "source": [
        "It may also be useful to look at attention maps for different examples:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1KM7dAFi7S1U"
      },
      "outputs": [],
      "source": [
        "# Please do not change anything in the following cell.\n",
        "\n",
        "def visualize_attention(src_glyphs, tgt_glyphs, attention, axes):\n",
        "    axes.matshow(attention.numpy(), cmap='bone')\n",
        "\n",
        "    axes.set_xticks(numpy.arange(len(src_glyphs)), labels=src_glyphs)\n",
        "    axes.set_yticks(numpy.arange(len(tgt_glyphs)), labels=tgt_glyphs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OixmEkuF7S1V",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "53803df2-4dde-495a-cd91-545a2eedaebd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "/usr/local/lib/python3.11/dist-packages/IPython/core/events.py:89: UserWarning: Glyph 2357 (\\N{DEVANAGARI LETTER VA}) missing from font(s) DejaVu Sans.\n",
            "  func(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/IPython/core/events.py:89: UserWarning: Matplotlib currently does not support Devanagari natively.\n",
            "  func(*args, **kwargs)\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "/usr/local/lib/python3.11/dist-packages/IPython/core/events.py:89: UserWarning: Glyph 2352 (\\N{DEVANAGARI LETTER RA}) missing from font(s) DejaVu Sans.\n",
            "  func(*args, **kwargs)\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "/usr/local/lib/python3.11/dist-packages/IPython/core/events.py:89: UserWarning: Glyph 2367 (\\N{DEVANAGARI VOWEL SIGN I}) missing from font(s) DejaVu Sans.\n",
            "  func(*args, **kwargs)\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "/usr/local/lib/python3.11/dist-packages/IPython/core/events.py:89: UserWarning: Glyph 2366 (\\N{DEVANAGARI VOWEL SIGN AA}) missing from font(s) DejaVu Sans.\n",
            "  func(*args, **kwargs)\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "/usr/local/lib/python3.11/dist-packages/IPython/core/events.py:89: UserWarning: Glyph 2332 (\\N{DEVANAGARI LETTER JA}) missing from font(s) DejaVu Sans.\n",
            "  func(*args, **kwargs)\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "/usr/local/lib/python3.11/dist-packages/IPython/core/events.py:89: UserWarning: Glyph 2350 (\\N{DEVANAGARI LETTER MA}) missing from font(s) DejaVu Sans.\n",
            "  func(*args, **kwargs)\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "/usr/local/lib/python3.11/dist-packages/IPython/core/events.py:89: UserWarning: Glyph 2348 (\\N{DEVANAGARI LETTER BA}) missing from font(s) DejaVu Sans.\n",
            "  func(*args, **kwargs)\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "/usr/local/lib/python3.11/dist-packages/IPython/core/events.py:89: UserWarning: Glyph 2346 (\\N{DEVANAGARI LETTER PA}) missing from font(s) DejaVu Sans.\n",
            "  func(*args, **kwargs)\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "/usr/local/lib/python3.11/dist-packages/IPython/core/events.py:89: UserWarning: Glyph 2344 (\\N{DEVANAGARI LETTER NA}) missing from font(s) DejaVu Sans.\n",
            "  func(*args, **kwargs)\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "/usr/local/lib/python3.11/dist-packages/IPython/core/events.py:89: UserWarning: Glyph 2340 (\\N{DEVANAGARI LETTER TA}) missing from font(s) DejaVu Sans.\n",
            "  func(*args, **kwargs)\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "/usr/local/lib/python3.11/dist-packages/IPython/core/events.py:89: UserWarning: Glyph 2381 (\\N{DEVANAGARI SIGN VIRAMA}) missing from font(s) DejaVu Sans.\n",
            "  func(*args, **kwargs)\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "/usr/local/lib/python3.11/dist-packages/IPython/core/events.py:89: UserWarning: Glyph 2370 (\\N{DEVANAGARI VOWEL SIGN UU}) missing from font(s) DejaVu Sans.\n",
            "  func(*args, **kwargs)\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "/usr/local/lib/python3.11/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 2357 (\\N{DEVANAGARI LETTER VA}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.11/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Matplotlib currently does not support Devanagari natively.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "/usr/local/lib/python3.11/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 2352 (\\N{DEVANAGARI LETTER RA}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "/usr/local/lib/python3.11/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 2367 (\\N{DEVANAGARI VOWEL SIGN I}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "/usr/local/lib/python3.11/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 2366 (\\N{DEVANAGARI VOWEL SIGN AA}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "/usr/local/lib/python3.11/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 2332 (\\N{DEVANAGARI LETTER JA}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "/usr/local/lib/python3.11/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 2350 (\\N{DEVANAGARI LETTER MA}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "/usr/local/lib/python3.11/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 2348 (\\N{DEVANAGARI LETTER BA}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "/usr/local/lib/python3.11/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 2346 (\\N{DEVANAGARI LETTER PA}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "/usr/local/lib/python3.11/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 2344 (\\N{DEVANAGARI LETTER NA}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "/usr/local/lib/python3.11/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 2340 (\\N{DEVANAGARI LETTER TA}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "/usr/local/lib/python3.11/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 2381 (\\N{DEVANAGARI SIGN VIRAMA}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "/usr/local/lib/python3.11/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 2370 (\\N{DEVANAGARI VOWEL SIGN UU}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Source Han Sans TW, sans-serif, Arial Unicode MS\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1000 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Please do not change anything in the following cell.\n",
        "\n",
        "pyplot.figure(figsize=(12, 10))\n",
        "\n",
        "src_id_to_token = inverse_vocabulary(src_tokenizer)\n",
        "tgt_id_to_token = inverse_vocabulary(tgt_tokenizer)\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i, row in train_data.sample(n=4, random_state=42, ignore_index=True).iterrows():\n",
        "        src_tokens = torch.tensor(src_tokenizer.encode(row['Name']))\n",
        "        attentions, tgt_tokens = model.attentions(src_tokens, tgt_tokenizer.get_special_tokens()['[EOS]'], max_length=50)\n",
        "        src_glyphs = apply_inverse_vocab(src_tokens.tolist(), src_id_to_token)\n",
        "        tgt_glyphs = apply_inverse_vocab(tgt_tokens.tolist(), tgt_id_to_token)\n",
        "        axes = pyplot.subplot(2, 2, i+1)\n",
        "        visualize_attention(src_glyphs, tgt_glyphs, attentions, axes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qE1PU0k9s8Ds"
      },
      "outputs": [],
      "source": [
        "# Please do not change anything in the following cell.\n",
        "\n",
        "output_data = []\n",
        "for _, row in validation_data.iterrows():\n",
        "    y_pred = rnn_greedy_generate(\n",
        "        model, row['Name'], src_tokenizer, tgt_tokenizer,\n",
        "        max_length = rnn_enc_dec_attn_data_params['tgt_padding']\n",
        "    )\n",
        "    output_data.append({ 'Name': row['Name'], 'Translation': y_pred })\n",
        "\n",
        "pd.DataFrame.from_records(output_data).to_csv(\n",
        "    os.path.join(DIRECTORY_NAME, \"rnn.enc-dec.attn\", \"outputs.csv\"), index=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aQ7Qndm47S1V"
      },
      "outputs": [],
      "source": [
        "# Please do not change anything in the following cell.\n",
        "\n",
        "# Release resources\n",
        "if 'trainer' in globals():\n",
        "    del trainer\n",
        "\n",
        "if 'model' in globals():\n",
        "    del model\n",
        "\n",
        "sync_vram()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "998loM887S1W"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_tm4zQ637S1W"
      },
      "source": [
        "In the last few modules, you have implemented different approaches towards transliteration of Indian names to English. To assess how well different systems perform, it is useful to compute different metrics, which assess different properties:\n",
        "\n",
        "- **Accuracy**: From a parallel corpus, number of translations the model got exactly right. Higher the better. Note that this makes sense only for this task. and lacks granularity.\n",
        "- **Edit Distance**: Number of edits at the character level (insertions, deletions, substitutions) required to transform your model's outputs to a reference translation. Lower the better.\n",
        "- **Character Error Rate (CER)**: The rate at which your system/model makes mistakes at the character level. Lower the better.\n",
        "- **Token Error Rate (TER)**: The rate at which your system/model makes mistakes at the token level. Lower the better. Depending on your tokenizer implementation, could be the same as CER.\n",
        "- **BiLingual Evaluation Understudy (BLEU)**: Proposed by [Papineni et al., 2002](https://aclanthology.org/P02-1040/), BLEU is a metric that assess the quality of a translation against reference translations through assessing n-gram overlap. Higher the better.\n",
        "\n",
        "Since accents and half-letters exist as separate characters in the Unicode specification, and can change the interpretation of the output, metrics that operate at the character level will treat these separately."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4V2mXdKh7S1W"
      },
      "outputs": [],
      "source": [
        "# Please do not change anything in the following cell.\n",
        "\n",
        "class Evaluator:\n",
        "    \"\"\" Class to handle all the logic concerning the evaluation of trained models.  \"\"\"\n",
        "\n",
        "    def __init__(self, src_tokenizer, tgt_tokenizer) -> None:\n",
        "        \"\"\" Initializes the evaluator.\n",
        "\n",
        "        Args:\n",
        "            src_tokenizer (Tokenizer): Tokenizer for input strings in the source language.\n",
        "            tgt_tokenizer (Tokenizer): Tokenizer for output strings in the target language.\n",
        "        \"\"\"\n",
        "\n",
        "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "        self.src_tokenizer = src_tokenizer\n",
        "        self.tgt_tokenizer = tgt_tokenizer\n",
        "        self.decoding_method = None\n",
        "\n",
        "    def set_decoding_method(self, decoding_method):\n",
        "        \"\"\" Sets the decoding method to use with models.\n",
        "                The evaluation function will use the set decoding method to generate outputs from the model.\n",
        "\n",
        "        Args:\n",
        "            decoding_method (function): Decoding method.\n",
        "                Must accept the model instance, the input string, and tokenizers as arguments.\n",
        "                Can accept additional arguments if required.\n",
        "        \"\"\"\n",
        "\n",
        "        self.decoding_method = decoding_method\n",
        "\n",
        "    @staticmethod\n",
        "    def decompose(string):\n",
        "        \"\"\" Decomposes a string into a set of tokens.\n",
        "\n",
        "        Args:\n",
        "            string (str): String to decompose.\n",
        "\n",
        "        Returns:\n",
        "            list[str]: List of characters from the string.\n",
        "        \"\"\"\n",
        "        return unicodedata.normalize('NFKD', string).encode('utf-8')\n",
        "\n",
        "    @staticmethod\n",
        "    def levenshtein_distance(string1, string2):\n",
        "        \"\"\" Computes the levensthein distance between two strings.\n",
        "\n",
        "        Args:\n",
        "            string1 (list[any]): Sequence A.\n",
        "            string2 (list[any]): Sequence B.\n",
        "\n",
        "        Returns:\n",
        "            tuple[int, int, int]: Number of insertions + deletions, substitutions and no-ops.\n",
        "        \"\"\"\n",
        "\n",
        "        costs = [\n",
        "            [ 0 for j in range(len(string2)+1) ]\n",
        "            for i in range(len(string1)+1)\n",
        "        ]\n",
        "\n",
        "        # Prepare matrix of costs.\n",
        "        for i in range(len(string1)+1): costs[i][0] = i\n",
        "        for j in range(len(string2)+1): costs[0][j] = j\n",
        "        for i in range(1, len(string1)+1):\n",
        "            for j in range(1, len(string2)+1):\n",
        "                costs[i][j] = min(\n",
        "                    costs[i][j-1] + 1,\n",
        "                    costs[i-1][j] + 1,\n",
        "                    costs[i-1][j-1] + (0 if string1[i-1] == string2[j-1] else 1)\n",
        "                )\n",
        "\n",
        "        # Decode matrix in backward manner for actual operation counts.\n",
        "        c_ins_del, c_sub, c_noop = 0, 0, 0\n",
        "\n",
        "        i, j = len(string1), len(string2)\n",
        "        while i > 0 or j > 0:\n",
        "            if i > 0 and costs[i][j] == costs[i-1][j] + 1:\n",
        "                c_ins_del += 1\n",
        "                i -= 1\n",
        "            elif j > 0 and costs[i][j] == costs[i][j-1] + 1:\n",
        "                c_ins_del += 1\n",
        "                j -= 1\n",
        "            elif i > 0 and j > 0:\n",
        "                if string1[i-1] == string2[j-1]:\n",
        "                    c_noop += 1\n",
        "                else:\n",
        "                    c_sub += 1\n",
        "                i, j = i-1, j-1\n",
        "            else:\n",
        "                break\n",
        "\n",
        "        return c_ins_del, c_sub, c_noop\n",
        "\n",
        "    @staticmethod\n",
        "    def accuracy(y_true, y_pred):\n",
        "        \"\"\" Computes the accuracy of the predictions, against a reference set of predictions.\n",
        "\n",
        "        Args:\n",
        "            y_true (list[str]): Actual translations.\n",
        "            y_pred (list[str]): Generated translations.\n",
        "\n",
        "        Returns:\n",
        "            float: Accuracy score, between 0 and 1.\n",
        "        \"\"\"\n",
        "        return sum(yi_true == yi_pred for yi_true, yi_pred in zip(y_true, y_pred)) / len(y_pred)\n",
        "\n",
        "    @classmethod\n",
        "    def char_error_rate(cls, y_true, y_pred):\n",
        "        \"\"\" Computes the character level error rate (CER) of the set of\n",
        "            predictions against the reference translations.\n",
        "\n",
        "        Args:\n",
        "            y_true (list[str]): Actual translations.\n",
        "            y_pred (list[str]): Generated translations.\n",
        "\n",
        "        Returns:\n",
        "            float: CER score, between 0 and 1. Lower the better.\n",
        "        \"\"\"\n",
        "\n",
        "        cer_score = 0\n",
        "\n",
        "        for yi_true, yi_pred in zip(y_true, y_pred):\n",
        "            yi_true, yi_pred = cls.decompose(yi_true), cls.decompose(yi_pred)\n",
        "            c_ins_del, c_sub, c_noop = cls.levenshtein_distance(yi_true, yi_pred)\n",
        "            cer_score += (c_ins_del + c_sub) / (c_ins_del + c_sub + c_noop)\n",
        "\n",
        "        return cer_score / len(y_true)\n",
        "\n",
        "    def token_error_rate(self, y_true, y_pred):\n",
        "        \"\"\" Computes the token level error rate (TER) of the set of\n",
        "            predictions against the reference translations.\n",
        "\n",
        "        Args:\n",
        "            y_true (list[str]): Actual translations.\n",
        "            y_pred (list[str]): Generated translations.\n",
        "\n",
        "        Returns:\n",
        "            float: TER score, between 0 and 1. Lower the better.\n",
        "        \"\"\"\n",
        "\n",
        "        ter_score = 0\n",
        "\n",
        "        for yi_true, yi_pred in zip(y_true, y_pred):\n",
        "            yi_true = self.tgt_tokenizer.encode(yi_true, add_start=False, add_end=False)\n",
        "            yi_pred = self.tgt_tokenizer.encode(yi_pred, add_start=False, add_end=False)\n",
        "            t_ins_del, t_sub, t_noop = self.levenshtein_distance(yi_true, yi_pred)\n",
        "            ter_score += (t_ins_del + t_sub) / (t_ins_del + t_sub + t_noop)\n",
        "\n",
        "        return ter_score / len(y_true)\n",
        "\n",
        "    @classmethod\n",
        "    def bleu_score(cls, y_true, y_pred):\n",
        "        \"\"\" Computes the average BLEU score of the set of predictions against the reference translations.\n",
        "\n",
        "            Uses default parameters and equal weights for all n-grams, with max N = 4. (Thus computes BLEU-4).\n",
        "            Uses a smoothing method for the case of missing n-grams.\n",
        "\n",
        "        Args:\n",
        "            y_true (list[str]): Actual translations.\n",
        "            y_pred (list[str]): Generated translations.\n",
        "\n",
        "        Returns:\n",
        "            float: BLEU-4 score, the higher the better.\n",
        "        \"\"\"\n",
        "\n",
        "        y_true = [ [ cls.decompose(yi) ] for yi in y_true ]\n",
        "        y_pred = [ cls.decompose(yi) for yi in y_pred ]\n",
        "\n",
        "        smoothing = bleu_score.SmoothingFunction()\n",
        "\n",
        "        return bleu_score.corpus_bleu(\n",
        "            y_true, y_pred,\n",
        "            smoothing_function=smoothing.method1\n",
        "        )\n",
        "\n",
        "    def evaluate(self, model_path, data, reference_outputs, **decoding_kwargs):\n",
        "        \"\"\" Performs the evaluation of a specified model over given data.\n",
        "\n",
        "        Args:\n",
        "            model_path (str): Path to load the model from. Must have a model.pt file.\n",
        "            data (list[str]): List of input strings to translate.\n",
        "            reference_outputs (list[str]): List of output strings to use as reference.\n",
        "            decoding_kwargs (dict[str, any]): Additional arguments to forward to the decoding method.\n",
        "                This could be for instance, max_length for a greedy decoding method.\n",
        "\n",
        "        Raises:\n",
        "            ValueError: If the decoding method is not set apriori.\n",
        "        \"\"\"\n",
        "\n",
        "        if self.decoding_method is None:\n",
        "            raise ValueError(f\"{self.evaluate.__name__}: no decoding method is set, assign before use.\")\n",
        "\n",
        "        # Load the model to the active device.\n",
        "        model = torch.load(os.path.join(model_path, 'model.pt'), map_location=self.device, weights_only=False)\n",
        "\n",
        "        # Set model use parameters.\n",
        "        model.to(self.device)\n",
        "        model.eval()\n",
        "\n",
        "        # Generate outputs.\n",
        "        generated_outputs = []\n",
        "        with torch.no_grad():\n",
        "            for seq_x in data:\n",
        "                generated_outputs.append(self.decoding_method(\n",
        "                    model, seq_x, self.src_tokenizer,\n",
        "                    self.tgt_tokenizer, **decoding_kwargs\n",
        "                ))\n",
        "\n",
        "        accuracy_score = self.accuracy(reference_outputs, generated_outputs)\n",
        "        cer_score      = self.char_error_rate(reference_outputs, generated_outputs)\n",
        "        ter_score      = self.token_error_rate(reference_outputs, generated_outputs)\n",
        "        blue_score     = self.bleu_score(reference_outputs, generated_outputs)\n",
        "\n",
        "        print(\"EVALUATION:\", \">\", \"accuracy:\", f\"{accuracy_score:.2%}\")\n",
        "        print(\"EVALUATION:\", \">\", \"CER     :\", f\"{cer_score:.2%}\")\n",
        "        print(\"EVALUATION:\", \">\", \"TER     :\", f\"{ter_score:.2%}\")\n",
        "        print(\"EVALUATION:\", \">\", \"BLEU    :\", f\"{blue_score:.4f}\")\n",
        "        print()\n",
        "\n",
        "        # Free resources once evaluation is complete.\n",
        "        del model\n",
        "        sync_vram()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R3DxXlLm7S1X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be5e4dd7-9b18-4d41-8efd-fd7f19b1b895"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EVALUATION: enc-dec-rnn\n",
            "EVALUATION: > accuracy: 41.75%\n",
            "EVALUATION: > CER     : 14.60%\n",
            "EVALUATION: > TER     : 26.82%\n",
            "EVALUATION: > BLEU    : 0.6980\n",
            "\n",
            "EVALUATION: enc-dec-rnn-attn\n",
            "EVALUATION: > accuracy: 43.50%\n",
            "EVALUATION: > CER     : 14.17%\n",
            "EVALUATION: > TER     : 27.06%\n",
            "EVALUATION: > BLEU    : 0.7260\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Please do not change anything in the following cell.\n",
        "\n",
        "evaluator = Evaluator(src_tokenizer, tgt_tokenizer)\n",
        "\n",
        "# Use greedy decoding for producing outputs.\n",
        "evaluator.set_decoding_method(rnn_greedy_generate)\n",
        "\n",
        "# Evaluate enc-dec-rnn\n",
        "print(\"EVALUATION:\", \"enc-dec-rnn\")\n",
        "evaluator.evaluate(\n",
        "    os.path.join(DIRECTORY_NAME, \"rnn.enc-dec\"),\n",
        "    validation_data['Name'], validation_data['Translation'],\n",
        "    max_length = rnn_enc_dec_data_params['tgt_padding']\n",
        ")\n",
        "\n",
        "# Evaluate enc-dec-rnn-attn\n",
        "print(\"EVALUATION:\", \"enc-dec-rnn-attn\")\n",
        "evaluator.evaluate(\n",
        "    os.path.join(DIRECTORY_NAME, \"rnn.enc-dec.attn\"),\n",
        "    validation_data['Name'], validation_data['Translation'],\n",
        "    max_length = rnn_enc_dec_attn_data_params['tgt_padding']\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jfI3NL8w7S1Y"
      },
      "source": [
        "## Decoding Strategy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "scHoXxoi7S1Y"
      },
      "source": [
        "A conditional language model aims to learn $P_\\theta(y | x)$, that is, the probability of the target sequence being $y$ when the input sequence is $x$. This is modeled as $P_{\\theta}(y | x) = \\prod_{i=1}^{|y|} {P_\\theta(y_i | x, y_{1:i-1})}$.\n",
        "\n",
        "For translation, our goal is to find the sequence that maximizes this conditional probability, i.e. $y^* = \\arg \\max_{y} P_\\theta(y | x)$. $y^*$ is then the 'best' translation for the input sequence $x$. However, computing probabilities for all possible $y$ to find the maximizer is intractable. As a result, decoding strategies are employed to produce reasonable approximations of $y^*$.\n",
        "\n",
        "In the last module, you evaluated your models through different metrics, but the approach for generating outputs from the model was fixed to greedy decoding, where at each time step, the token to be produced is determined by $y_{i,greedy} := \\arg \\max_{y_i} P(y_i| x, y_{1:i-1})$. While this approach is fast, $P(y_{greedy}|x)$ may be much less than $P(y^*|x)$. Fortunately, better decoding strategies exist to produce better approximations, however at the cost of higher time complexity. One such strategy is:\n",
        "\n",
        "- **Beam-Search Decoding**: At every time step, retains $k$ candidate token generations, which are decoded individually (each path is referred as a beam) to obtain $k$ successors per beam. For the next time step, the best $k$ candidates are retained such that conditional probability of the sequence generated so far is maximized. Has a complexity of $O(kV|y|)$, where $V$ is the size of the target vocabulary, and $|y|$ is the target sequence length. Using $k=1$ makes it equivalent to greedy decoding. Implementations also employ length penalties to not be biased towards larger target sequences.\n",
        "\n",
        "In the next cell, you will implement the above explained Beam-Search Decoding decoding strategy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x4sw-Wrb7S1Z"
      },
      "outputs": [],
      "source": [
        "def rnn_better_generate(model, seq_x, src_tokenizer, tgt_tokenizer, max_length, k=5, length_penalty_alpha=0.6):\n",
        "    \"\"\" Given a source string, translate it to the target language using the trained model.\n",
        "        Uses beam search decoding to approximate the best translation.\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): RNN Type Encoder-Decoder Model.\n",
        "        seq_x (str): Input string to translate.\n",
        "        src_tokenizer (Tokenizer): Source language tokenizer.\n",
        "        tgt_tokenizer (Tokenizer): Target language tokenizer.\n",
        "        max_length (int): Maximum length of the target sequence to decode.\n",
        "        k (int, optional): Beam size.\n",
        "        length_penalty_alpha (float, optional): Length penalty exponent.\n",
        "\n",
        "    Returns:\n",
        "        str: Generated translation.\n",
        "    \"\"\"\n",
        "\n",
        "    # BEGIN CODE : enc-dec-rnn.better_generate\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        # 1) Convert source string to tensor on model.device\n",
        "        src_ids = [src_tokenizer.encode(seq_x)]\n",
        "        src_tensor = torch.tensor(src_ids, device=model.device)\n",
        "\n",
        "        # 2) Retrieve BOS and EOS token IDs from target tokenizer.\n",
        "        bos_token = tgt_tokenizer.get_special_tokens()['[BOS]']\n",
        "        eos_token = tgt_tokenizer.get_special_tokens()['[EOS]']\n",
        "\n",
        "        # 3) Prime the model: initial call using a single BOS token.\n",
        "        bos_tensor = torch.tensor([[bos_token]], device=model.device)\n",
        "        logits, hidden = model(src_tensor, bos_tensor, decoder_hidden_state=None)\n",
        "        # Get log probabilities (with softmax then log) for first token.\n",
        "        log_probs = torch.log_softmax(logits[:, -1, :], dim=-1).squeeze(0)  # shape: [vocab_size]\n",
        "\n",
        "        # 4) Initialize beams: each beam is a tuple (token_seq, cumulative_log_prob, hidden_state)\n",
        "        topk_log_probs, topk_indices = log_probs.topk(k, dim=-1)\n",
        "        topk_log_probs = topk_log_probs.tolist()\n",
        "        topk_indices = topk_indices.tolist()\n",
        "\n",
        "        beams = []\n",
        "        for i in range(len(topk_indices)):\n",
        "            token = topk_indices[i]\n",
        "            score = topk_log_probs[i]\n",
        "            beams.append(([token], score, hidden))\n",
        "\n",
        "        # 5) Beam Search Loop (start from step 1, since first token is produced)\n",
        "        for _ in range(max_length - 1):\n",
        "            new_beams = []\n",
        "            for seq, cum_score, beam_hidden in beams:\n",
        "                # If last token is EOS, retain beam as is.\n",
        "                if seq[-1] == eos_token:\n",
        "                    new_beams.append((seq, cum_score, beam_hidden))\n",
        "                    continue\n",
        "                # Prepare current input from last token of this beam.\n",
        "                input_tensor = torch.tensor([[seq[-1]]], device=model.device)\n",
        "                logits, new_hidden = model(src_tensor, input_tensor, beam_hidden)\n",
        "                log_probs = torch.log_softmax(logits[:, -1, :], dim=-1).squeeze(0)  # [vocab_size]\n",
        "                topk_log_probs, topk_indices = log_probs.topk(k, dim=-1)\n",
        "                topk_log_probs = topk_log_probs.tolist()\n",
        "                topk_indices = topk_indices.tolist()\n",
        "                for j in range(len(topk_indices)):\n",
        "                    token = topk_indices[j]\n",
        "                    score = topk_log_probs[j]\n",
        "                    new_seq = seq + [token]\n",
        "                    new_cum_score = cum_score + score\n",
        "                    new_beams.append((new_seq, new_cum_score, new_hidden))\n",
        "            # Apply length penalty: adjusted_score = cum_score / (length ^ alpha)\n",
        "            new_beams = sorted(new_beams, key=lambda b: b[1] / (len(b[0]) ** length_penalty_alpha), reverse=True)\n",
        "            beams = new_beams[:k]\n",
        "            # If all beams end with EOS, break early.\n",
        "            if all(b[0][-1] == eos_token for b in beams):\n",
        "                break\n",
        "\n",
        "        # 6) Select the best beam (with highest adjusted score)\n",
        "        best_beam = max(beams, key=lambda b: b[1] / (len(b[0]) ** length_penalty_alpha))\n",
        "        best_sequence = best_beam[0]\n",
        "        # Optionally, remove EOS if present.\n",
        "        if best_sequence and best_sequence[-1] == eos_token:\n",
        "            best_sequence = best_sequence[:-1]\n",
        "\n",
        "        return tgt_tokenizer.decode(best_sequence)\n",
        "\n",
        "    # END CODE\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PhMFQmhY7S1Z"
      },
      "outputs": [],
      "source": [
        "# BEGIN CODE : decoding.init\n",
        "\n",
        "decoding_params = dict(\n",
        "    k=6,\n",
        "    length_penalty_alpha=0.9)\n",
        "\n",
        "# END CODE\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aOwxnBIC7S1a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfaac557-8386-4112-e143-259ababfe0bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EVALUATION: enc-dec-rnn\n",
            "EVALUATION: > accuracy: 43.00%\n",
            "EVALUATION: > CER     : 13.77%\n",
            "EVALUATION: > TER     : 25.76%\n",
            "EVALUATION: > BLEU    : 0.7135\n",
            "\n",
            "EVALUATION: enc-dec-rnn-attn\n",
            "EVALUATION: > accuracy: 45.00%\n",
            "EVALUATION: > CER     : 13.57%\n",
            "EVALUATION: > TER     : 26.16%\n",
            "EVALUATION: > BLEU    : 0.7383\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Please do not change anything in the following cell.\n",
        "\n",
        "evaluator = Evaluator(src_tokenizer, tgt_tokenizer)\n",
        "evaluator.set_decoding_method(rnn_better_generate)\n",
        "\n",
        "# Evaluate enc-dec-rnn\n",
        "print(\"EVALUATION:\", \"enc-dec-rnn\")\n",
        "evaluator.evaluate(\n",
        "    os.path.join(DIRECTORY_NAME, \"rnn.enc-dec\"),\n",
        "    validation_data['Name'], validation_data['Translation'],\n",
        "    max_length = rnn_enc_dec_data_params['tgt_padding'],\n",
        "    **decoding_params\n",
        ")\n",
        "\n",
        "# Evaluate enc-dec-rnn-attn\n",
        "print(\"EVALUATION:\", \"enc-dec-rnn-attn\")\n",
        "evaluator.evaluate(\n",
        "    os.path.join(DIRECTORY_NAME, \"rnn.enc-dec.attn\"),\n",
        "    validation_data['Name'], validation_data['Translation'],\n",
        "    max_length = rnn_enc_dec_attn_data_params['tgt_padding'],\n",
        "    **decoding_params\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yHm5Di5V7S1a"
      },
      "source": [
        "## Congratulations!"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e3739444e5a8415782f9db32b64378f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ccc9f4ca8ced4f628d39641423999473",
              "IPY_MODEL_da0278062bcb442c88164751ffcd2f8f",
              "IPY_MODEL_c54790fc62f4407cbf5a987c4f95db99"
            ],
            "layout": "IPY_MODEL_5544af0fdcb74bc781d91bfadf5aa9f4"
          }
        },
        "ccc9f4ca8ced4f628d39641423999473": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_edef9af3544d49c1a664a187e00585e8",
            "placeholder": "​",
            "style": "IPY_MODEL_ef3b20958c0e4572b6e3987b551dbc44",
            "value": "Epoch 10 / 10: 100%"
          }
        },
        "da0278062bcb442c88164751ffcd2f8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d79c93db485442ab9fbbe9232739603f",
            "max": 500,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_17386cff138444a58635d937917b7812",
            "value": 500
          }
        },
        "c54790fc62f4407cbf5a987c4f95db99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c1b808864c9342988fadac5720b0ff97",
            "placeholder": "​",
            "style": "IPY_MODEL_883bf5e61558479bbe764495256f7b39",
            "value": " 500/500 [01:12&lt;00:00,  7.47it/s, batch=50, loss=0.0864]"
          }
        },
        "5544af0fdcb74bc781d91bfadf5aa9f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "edef9af3544d49c1a664a187e00585e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef3b20958c0e4572b6e3987b551dbc44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d79c93db485442ab9fbbe9232739603f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17386cff138444a58635d937917b7812": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c1b808864c9342988fadac5720b0ff97": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "883bf5e61558479bbe764495256f7b39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b3357e49d2654713a755e4eeacd09674": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9ef00b5410fa4cbd8d7252dee6544be6",
              "IPY_MODEL_620036822af04b28b54d16f974636b1a",
              "IPY_MODEL_39e47b7d966c44eabb5a25d892a85a3c"
            ],
            "layout": "IPY_MODEL_4d10ee56b2e445d9b8fae1667bd5829a"
          }
        },
        "9ef00b5410fa4cbd8d7252dee6544be6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d9ab4b5ecfa148febf2196dbe988273d",
            "placeholder": "​",
            "style": "IPY_MODEL_c72ed7d9e2aa478db6c5ecddeb15835b",
            "value": "Epoch 30 / 30: 100%"
          }
        },
        "620036822af04b28b54d16f974636b1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b6ad4374e1f546cf93d89a0b0d704e9a",
            "max": 4230,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_457fa2b31ff847e0b5e4dd4b280af5e8",
            "value": 4230
          }
        },
        "39e47b7d966c44eabb5a25d892a85a3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_46110e09f0a74682a21e804d2b2e839d",
            "placeholder": "​",
            "style": "IPY_MODEL_5fd3ea20471347ed879da2cbaed0c3c7",
            "value": " 4230/4230 [18:13&lt;00:00,  4.01it/s, batch=141, loss=0.0813]"
          }
        },
        "4d10ee56b2e445d9b8fae1667bd5829a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9ab4b5ecfa148febf2196dbe988273d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c72ed7d9e2aa478db6c5ecddeb15835b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b6ad4374e1f546cf93d89a0b0d704e9a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "457fa2b31ff847e0b5e4dd4b280af5e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "46110e09f0a74682a21e804d2b2e839d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5fd3ea20471347ed879da2cbaed0c3c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "880f59f092474eb78bb147e00bbe62ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ceef0d49d744492487951bd016cdfdcc",
              "IPY_MODEL_2d512b1578924f9a84c1d7e5352c701c",
              "IPY_MODEL_f7f1c812167e4a8fbd38800585052e7d"
            ],
            "layout": "IPY_MODEL_44324d2c672646d8af506ed9b3e9dc1e"
          }
        },
        "ceef0d49d744492487951bd016cdfdcc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_522cc2279ba0421292f1a76a49e528bc",
            "placeholder": "​",
            "style": "IPY_MODEL_f15a4b62faab43d5a5b9e3d5520d5dbc",
            "value": "Epoch 30 / 30: 100%"
          }
        },
        "2d512b1578924f9a84c1d7e5352c701c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_93fe5e61a67441d3923a9426b959e9a5",
            "max": 8430,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_13cd038ec5c6403f9a268964529ebbb1",
            "value": 8430
          }
        },
        "f7f1c812167e4a8fbd38800585052e7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ec9926dd96b46679b6fd9efd0ab3471",
            "placeholder": "​",
            "style": "IPY_MODEL_91a82428b3254159b8a6a156f8f020fc",
            "value": " 8430/8430 [39:03&lt;00:00,  3.87it/s, batch=281, loss=0.0385]"
          }
        },
        "44324d2c672646d8af506ed9b3e9dc1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "522cc2279ba0421292f1a76a49e528bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f15a4b62faab43d5a5b9e3d5520d5dbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "93fe5e61a67441d3923a9426b959e9a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13cd038ec5c6403f9a268964529ebbb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6ec9926dd96b46679b6fd9efd0ab3471": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91a82428b3254159b8a6a156f8f020fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}